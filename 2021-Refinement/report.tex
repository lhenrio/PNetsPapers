\documentclass{article}

\usepackage{xunicode}
\usepackage{fontspec}
\usepackage[hmargin=0.5in,marginparwidth=1.5in,includemp]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{unicode-math}
\usepackage{tikz}
\usetikzlibrary{external}
\usepackage[colorlinks]{hyperref}
\AtBeginDocument{\renewcommand\setminus{\smallsetminus}}
\usepackage{polyglossia}
\setmainlanguage{english}

\input{common.tex}
\input{preamble.tex}
\input{tikzmacros.tex}

% transitions between sections
% TODO: CITER LES CONFERENCES

\title{Refinement for open automata}
\author{Quentin \textsc{Corradi}}

\begin{document}
\maketitle

\section{Introduction}
The open automata model is used to give the semantic of open pNets \cite{2007.10770}.
Open pNets are not petri nets but an intermediate representation used in the VerCors project to perform verification \cite{henrio:01252323}.
Verification is the process of checking that an implementation satisfies a specification.
Open pNets with the open automaton semantics and equivalence relation introduced in previous work \cite{2007.10770} were sucessfully used to model and verify BIP and GCM \cite{qin:01823507, ameurboulifa:01526055}.
However equivalences relations are not always sufficient to perform verification, refinement relations are also used.
For instance an example of open pNet where equivalence is not sufficient was encountered in an article about algorithms fo weak bisimulation on open automata \cite{wang:03126313}.

The contributions of this article are the definition of composition for open automata without having to define open pNets, and the introduciton of several refinement relations for open automata\marginpar{TODO: expand}.

% Related work: thesis

We begin with Section \ref{sec:notations} by giving some notations used throughout this paper.
Then there are several sections dedicated to define all the interesting objects and properties:
In Section \ref{sec:def} we give a clean and up to date definition of open automata.
In Section \ref{sec:comp} we define their composition without requiring the use of open pNets.
In Section \ref{sec:proofelts} we adapt the standard properties related to refinement relation from LTS to open automata.
After that Section \ref{sec:prelref} is dedicated to progressively build a refinement relation.
Section \ref{sec:refinement} introduces and analyses the refinement relation on open automata.
% future work
% conclusion


\section{Notations}\label{sec:notations}
Notations will be defined with the operator \(\defnotation\) and names are given with the operator \(\defobject\) as follows:
\begin{align*}
	\mathit{notation\_with\_variables} & \defnotation \mathit{notated\_object\_using\_the\_variables} \\
	\mathit{name} & \defobject \mathit{fully\_defined\_mathematical\_object}
\end{align*}

Throughout this paper, tuples will be noted differently depending on what they represent.
This helps distinguishing the manipulated objects.
Every such notation will be introduced in the definition of the object.

Families of values, or equivalently maps will be noted \(\mset{i \mapsto x_i}{i \in I}\), \(\mset{i \gets x_i}{i \in I}\) or \(x_i^{i \in I}\).
The latter can only be used if there is a generating expression; for instance \(\mpar{ax}^{x \in \setR}\) represents a scaling function, \(c^{i \in I}\) is a constant function over \(I\).
However \(\mbrc{\alpha \mapsto 1, \beta \mapsto 2, \gamma \mapsto 3}\) has no generating expression and is represented here with the finite version of first notation.
The disjoint union of two maps \(\varphi: I \to X\) and \(\psi: J \to Y\) with \(I \cap J = \emptyset\) is \(\varphi \uplus \psi: I \uplus J \to X \cup Y\).

In a formula, a quantifier followed by a finite set will be used as a shorthand for the quantification on every variable in the set:
\(\forall \mbrc{a_1, \dots, a_n}, \exists \mbrc{b_1, \dots, b_m}, P\) means \(\forall a_1, \dots, \forall a_n, \exists b_1, \dots, \exists b_m, P\).


\section{Open Automata}\label{sec:def}
To define the open automata we need some preliminary definitions.
\begin{defi}[Expression algebra, Action algebra, Formulas, Terms]
An expression algebra \(E\) is a disjoint union \(E \defobject \terms \uplus \actions \uplus \formulas\) of the terms, the actions and the formulas.

The terms \(\terms\) is a term algebra\marginpar{reference to come}.
As any term algebra it has constant symbols with arity, variables, and a typing mechanism to distinguish well-formed and ill-formed terms.
The action algebra \(\actions\) is another term algebra.
It can be a subset of the terms.
The formulas \(\formulas\) are at least the first order formulas over \(\terms\) and \(\actions\).
\end{defi}
The term algebras are arbitrary.
The formulas contain at least first order logic terms with an equality relation.
This equality relation is not necessarily a syntactic equality (\(2 + 2 \neq 4\) with a syntactic equality).

An example of term algebra can be Peano integers (constant zero with arity 0, constant successor function with arity 1 and the variables), the formulas associated can use syntactic equality relation, the sum relation \(\mathit{sum}\mpar{a, b, c}: \text{``}a = b + c\text{"}\) and the product relation \(\mathit{prod}\mpar{a, b, c}: \text{``}a = b \times c\text{"}\).

\begin{defi}[Unbound variables, Expressions restricted to variables, Closed expressions]
\defitem \(\fvars{e}\) is the set of variables in \(e \in E\) that are not bound by any binder.
	Binders can be for instance quantifiers in formulas, or let-binders in terms if they are part of the term algebra.
\defitem The expressions restricted to variables in \(V\) are \(E_V \defnotation \mset{e \in E}{\fvars{e} \subseteq V}\); \(E_V \subset E\).
\defitem The closed expressions are expressions restricted to variables in \(\emptyset\), \(E_\emptyset\).
\end{defi}
Terms, actions and formulas restricted to variables and their closed versions are also defined by restriction.
A closed expression can contain variables under a binder, only unbound variable are forbidden.

We can use the previous example of first order formula on Peano integers to illustrate these definitions.
\(x\), \(S\mpar{y}\) are well-formed terms, \(0\) is a closed term, \(\fvars{x} = \mbrc{x}\), \(\fvars{S\mpar{y}} = \mbrc{y}\), \(\fvars{0} = \emptyset\).
\(x = 0\), \(\forall y, \exists x, \mathit{sum}\mpar{y, z, x}\) are valid formulas, \(\forall x, \neg S\mpar{x} = 0\) is a valid closed formula, \(\fvars{x = 0} = \mbrc{x}\), \(\fvars{\forall y, \exists x, \mathit{sum}\mpar{y, z, x}} = \mbrc{z}\), \(\fvars{\forall x, \neg S\mpar{x} = 0} = \emptyset\).

\begin{defi}[Values, Satisfiability, (Parallel) substitution]
We assume that the following are given:
\defitem The values \(\values\), which are interpretations of closed terms.
\defitem The satisfiability relation on closed formulas, \({\vdash} f\) where \(f \in \rformulas\).
\defitem The substitution in \(e \in E\) of \(x \in \fvars{e}\) by \(t \in \terms\), \(e\subst{t}{x}\).
\defitem The parallel substitution in \(e \in E\) of variables in \(V\) by \(\psi: V \to \terms\), \(e\psubst{\psi}\).
\end{defi}
For the parallel substitution, the set \(V\) is not required to be a subset of \(\fvars{e}\).
In the case it isn't, the variables in \(V \setminus \fvars{e}\) are not substituted.
The substitutions might give a ill-formed expression; for instance let the terms be integers and pairs with (pointwise) addition, \(\mpar{a + b}\psubst{a \mapsto 7, b \mapsto \mpar{4, 5}}\) is a ill-formed term.
This can be guarded with the check \(e\subst{t}{x} \in E\) and \(e\psubst{\psi} \in E\) and it will implicitly be the case, for instance when there is quantification on \(t\) and \(\psi\), to simplify notations.

The interpretation of terms is supposed to be decidable.
The satisfiability of formulas might not be decidable nor complete nor consistent, however we will pretend like they are because these are really hard problems for logicians that we don't want to deal with.
For instance a formula with quantifiers on variables might not be provable even if it is true for all values of these variables.
In practise the formulas will be given to a SMT solver and we cannot always make sure they have all the previous properties.
\(\vdash\) can hence be interpreted as an indicator of what is given to the SMT; it separates the external logic and the logic on \(\formulas\).

Values will be used for keeping a variable state, and then injected in terms for substitution.
This is correct when \(\values \subseteq \rterms\) and we suppose it is the case.
Otherwise it doesn't invalidates theorems because it can stand as a shorthand for substitution with any term which is interpreted the kept value.
We suppose that the interpretation of terms is compatible w.r.t.\@ substitution, that is if two terms \(t\), \(t'\) are interpreted with the same value, then replacing \(t\) by \(t'\) in a well-formed expression makes an equivalent well-formed expression.
\begin{noti}[Notations for separating external logic and logic on \(\formulas\)]
\defitem The satisfiability of a formula \(f \in \formulas\) under some valuation \(\sigma: V \to \values\) is noted:
\[ \sigma \vdash f \defnotation \vdash \exists \fvars{f\psubst{\sigma}}, f\psubst{\sigma} \]
\defitem The satisfiability of a formula \(f \in \formulas\) with some variable set \(V\) as context is noted:
\[ V \vdash f \defnotation \vdash \forall V, \exists\mpar{\fvars{f} \setminus V}, f \]
\defitem The precedence of \(\vdash\) is the lowest on the right side and higher than \(\uplus\) on the left side:
\[ \forall a \, b, a \uplus b \vdash x \wedge y \implies \exists z, P\mpar{x,z} \text{ is the same as } \forall a \, b, \bigg((a \uplus b) \vdash \Big((x \wedge y) \implies \exists z, P\mpar{x,z}\Big)\bigg) \]
\end{noti}
With these common definitions and notations settled, the objects of interest can now be defined.
\begin{defi}[Open automaton]
A open automaton is a tuple \(\OAg\) with \(S\) the set of states, \(s_0 \in S\) the initial state, \(V\) the set of variable names unique to this automaton, \(\sigma_0: V' \to \values\) the initial valuation of variables where \(V' \subseteq V\), \(J\) the set of hole names and \(T\) the set of open transitions.
A pair of a state and a valuation is called a configuration.

\(S, V, J\) are arbitrary finite sets. % OR finite arbitrary sets?
\end{defi}
The variable names may clash when considering two automata, in this case we suppose that we can still distinguish the variables in the formulas.
In practise the open automata are used in a toolchain at a point where what came before guarantees there are no name clash, which is why we make this assumption.

The initial valuation may be a partial valuation of the variables.
If an undefined variable is set before being read, it behaves like an initially set variable.
If an undefined variable is not set before being read then its value may be any fixed value.
When refining the automaton it can be set by the implementation, or it can be left unspecified as a parameter of the automaton (for instance a \(n\) bits register has \(n\) as parameter).
\begin{defi}[Open transition]
An open transition is a tuple \nmm{\OTg} with \(s, s' \in S\) the source and target states, \(\alpha \in \actions\) the produced action, \(J' \subseteq J\) the holes involved in the transition, \(\beta_j \in \actions\) the actions of the holes, \(g \in \formulas\) the guard and \(\psi: V \to \terms\) the variables assignements.
\end{defi}
An open transition can have many unbound variables.
Actually an effective transition of the automaton is any well-formed substitution of the unbound variables of the transition minus the automaton variables.

The intuition of an open automaton is a partially defined LTS with variables, guards on transitions and parametrised actions.
Initially the automaton is in the initial state with an extension on all the variables of the initial valuation.
In any configuration, it can perform effective transitions which source state is the current state and which guard is satisfiable in the current valuation if the holes emit the indicated actions.
An effective transition is a transition where every variable that is not an automaton variable is instanciated with a value.
By performing the effective transition, the automaton emits the indicated action and updates its configuration according to the target state and variables assignements.

\begin{noti}[FH-bisimulation]
The FH-bisimulation \cite{henrio:01055091} is noted \(\cong\).

The FH-bisimulation is currently the only equivalence relation on open automata.
\end{noti}
To illustrate these definitions we consider two implementations (figure \ref{fig:enable}) of the LOTOS \cite{ISOLOTOS} operator enable in the open automata model.
The enable operator runs  the left hand side agent until it chooses to finish, at which point it produces an action \(\delta\mpar{t}\) (with \(t\) some data) that is synchronised with the first action of the right hand side agent which must be \(\act{accept}\mpar{t}\) (here \(t\) is an input), then only the latter agent runs.
The \(\act{accept}\) action is shortened as \(\act{acc}\) in the examples.
During the synchronised action, the value returned by first agent is passed to the second agent.
\begin{exi}[Enable, state-oriented]
Graphical convention for drawing automata are as follows.
As standard automata, circles represent states and simple arrows represent transitions.
The initial state is indicated by a double circle.
States names are indicated inside the circles and transitions labels are drawn near their corresponding arrow.
The open transitions do not indicate the source and target states since that is the role of the transitions arrows; only the emmited action is on the bottom side of open transitions.
Initial valuations are indicated near a double lined arrow pointing to the initial state.

\begin{figure}
\centering
\input{enable_state.tex}
\vrule
\input{enable_var.tex}
\caption{Enable operator implementation with open automata, on the left state oriented, on the right data oriented}
\label{fig:enable}
\end{figure}
The automaton on the left side of the figure is \(\OA{\mbrc{L, R}}{L}{\emptyset}{\mbrc{}}{\mbrc{l, r}}{T}\) where transitions in \(T\) are:
\begin{align*}
	\OT{L}{L}{x}{\mbrc{l \mapsto x}}{\forall y, x \neq \delta\mpar{y}}{\mbrc{}} &&
	\OT{L}{R}{\tau}{\mbrc{l \mapsto \delta\mpar{x}, r \mapsto \act{acc}\mpar{y}}}{x = y}{\mbrc{}} &&
	\OT{R}{R}{x}{\mbrc{r \mapsto x}}{\top}{\mbrc{}}
\end{align*}
Note that the transition in the middle could have been expressed as \(\mbrc{l \mapsto \delta\mpar{x}, r \mapsto \act{acc}\mpar{x}}\).
It would have avoided many effective transitions with trivially false guards like the one where \(x \mapsto 1, y \mapsto 2\), which has the guard \(1 = 2\).

This automaton is an implementation of the enable operator because it begins in the state \(L\), where it allows any non \(\delta\) transition from its hole \(l\), then the automaton synchronises its holes on the same data, effectively allowing a data exchange when it goes into state \(R\), and finally allows any transition from its hole \(r\).
The implementation of value passing in the open automata model doesn't distinguish input and output variables as in LOTOS.
Both holes must emit their actions with valid data to perform the transition in the enable operator.
If it is not possible the system is locked.

We use the standard convention that uses \(\tau\) as a non-observable transition, never synchronised with other actions and passed unmodified.
This allows the synchronisation of the two holes to be hidden to the exterior by sending a \(\tau\).
However here \(\tau\) is not always allowed from the holes, for instance in the state \(L\) the hole \(r\) cannot emit it.
These transitions have been omitted for the sake of simplifying the first example of open automata.
\end{exi}
Finally we can define some utilitary functions:
\begin{defi}[Guard, Out-transition, Transition variables]
Let \(V\) be the variable names of the considered automaton, \(T\) its transitions and \(r\) one of its states.
\(\fOT{r}\) are called the out-transitions of \(r\).
\(\fIT{r}\) are called the in-transitions of \(r\).
The local variables of a transition are all variables appearing in that transition except the global variables of the automaton.
\begin{align*}
	\fOT{r} & \defnotation \mset{\OTg \in T}{s = r} &
	\fIT{r} & \defnotation \mset{\OTg \in T}{s' = r} \\
\end{align*}
\vspace{-1cm}
\begin{gather*}
	\fguard{\OTg} \defnotation g \\
	\fvars{\OTg} \defnotation \mpar{\fvars{\alpha} \cup \fvars{g} \cup \bigcup_{j \in J'} \fvars{\beta_j} \cup \bigcup_{v \in V} \fvars{\psi\mpar{v}}} \setminus V
\end{gather*}
\end{defi}
The goal of the extractor \(\fvars{t}\) when \(t\) is a transition is to get variables that are unique to that transition.
Other variables like automaton variables are already known at this point so there is no use in getting them.
Also the use of this extractor benefits from this exclusion: otherwise there would always be \(\setminus V\) following it to prevent variable shadowing.

\begin{exi}[Enable, variable-oriented]
The automaton drawn on the right side of Figure \ref{fig:enable} is \(\OA{\mbrc{»}}{»}{\mbrc{v}}{\mbrc{v \mapsto l}}{\mbrc{l, r}}{T}\) where transitions in \(T\) are:
\begin{align*}
	\OT{»}{»}{x}{\mbrc{l \mapsto x}}{v = l \wedge x \neq \delta}{\mbrc{}} &&
	\OT{»}{»}{\tau}{\mbrc{l \mapsto \delta\mpar{x}, r \mapsto \act{acc}\mpar{y}}}{v = l \wedge x = y}{\mbrc{v \gets r}} &&
	\OT{»}{»}{x}{\mbrc{r \mapsto x}}{v = r}{\mbrc{}}
\end{align*}
It is an alternative implementation of the enable operator which is FH-bisimilar to the previous one \cite{henrio:01299562}.
Note that in this example \(r\) and \(l\) are a hole names and also closed terms: this is a naming conflict, though it is not ambiguous because \(J \cap \rterms = \emptyset\) always holds.
The variables local to a transition are all the unbound variables in the expressions minus the automaton variables.
For instance \(v\) is a variable of the automaton (used in the guard).
It is not local to the transition.
In a run, when taking effective transitions (without local variables), its value is not substituted with a closed term.
For instance \nmm{\OT{»}{»}{\tau}{\mbrc{l \mapsto \tau}}{v = l \wedge \tau \neq \delta}{\mbrc{}}} is an effective transition generated from the second transition but not \nmm{\OT{»}{»}{\tau}{\mbrc{l \mapsto \tau}}{l = l \wedge \tau \neq \delta}{\mbrc{}}} (result of the forbidden substitution \(v \mapsto l\)).

An imaginary run of this open automaton can be: The automaton in the hole \(l\) emits many actions, this synchronises with the only transition possible at that moment because \(v = l\).
Then the automaton in hole \(l\) emits a \(\delta\mpar{t}\), this is synchonised with the action that sets \(v \gets r\) and the automata in hole \(r\) must emit a \(\act{acc}\mpar{t}\).
Finally the automaton in the hole \(r\) emits any sequence of actions.

Another imaginary run can be: The automaton in the hole \(l\) emits a sequence of non \(\delta\mpar{t}\) actions so the automaton in the hole \(r\) cannot emit a \(\act{acc}\mpar{t}\) and never runs.
\end{exi}

From this point open automata and open transitions can be called automata and transitions for simplicity. % NEED NORMALISATION, LEFT IN CASE OF OMISSION


\section{Composition of Open Automata}\label{sec:comp}
Open automata are partially specified automata, part of that partiality comes from the holes.
The interpretation of a hole is an interface with another open automaton, in which we can plug an open automaton with an operation called composition.
In this article, composition will only refer to filling holes, other compositions like ``parallel composition" (pure interleaving) are not tackled.
The composition of open automata was already implicitely defined by the means of composition on pNets in previous work \cite{henrio:01299562} but never completely formalised on open automata.
The definition of composition below is a direct translation of what happens with pNets composition without the need of introducing pNets.
\begin{defi}[Composition of open automata]
The composition of \(A_c \defobject \OAg[c]\) in the hole \(k \in J_p\) of \(A_p \defobject \OAg[p]\) is
\begin{align*}
	A_p\subst{A_c}{k} \defnotation & \OA{S_p \times S_c}{\mpar{s_{0p}, s_{0c}}}{V_p \uplus V_c}{\sigma_{0p} \uplus \sigma_{0c}}{J_c \uplus J_p \setminus \mbrc{k}}{T} \\
	\text{with } T \defobject & \mset{\OT{\mpar{s_p, s_c}}{\mpar{s'_p, s'_c}}{\alpha_p}{\beta_j^{j \in J'_c \uplus J'_p \setminus \mbrc{k}}}{g_p \wedge g_c \wedge \alpha_c = \beta_k}{\psi_p \uplus \psi_c}}{\OTx{p}{}{}{p} \in T_p, \OTx{c}{}{}{c} \in T_c} \\
	& \cup \mset{\OT{\mpar{s_p, s_c}}{\mpar{s'_p, s_c}}{\alpha_p}{\beta_j^{j \in J'_p}}{g_p}{\psi_p}}{\OTx{p}{}{}{p} \in T_p, k \notin J'_p, s_c \in S_c}
\end{align*}
\end{defi}
The action emitted when \(A_c\) makes a transition is sychronised with the action of the hole \(k\) in transitions of \(A_p\) which have it as a hole action (first transition set, \(\alpha_c = \beta_k\)).
The composition may look like a handshake, with both automata running in parallel (product of states and joint variables) however it is asymmetric because of the second transition set (\(k \notin J'_p\)):
No transition of \(A_c\) is performed when a transition that do not refer to the hole \(k\) is performed in \(A_p\).

Composition is a complex process that generates big automata with complex and potentially simplifiable transitions.
However simplification is a hard problem that is not yet automatised on open automata, so from this point the guards and transitions will always be simplified by hand without further explaination.
An example of composition can be found in Appendix \ref{apx:composition}.
\begin{prop}[Simultaneous composition]
Let \(A_1\), \(A_2\), \(A_3\) be three open automata with respectively \(J_1\), \(J_2\) and \(J_3\) as hole names.
We have
\begin{align*}
	A_1\subst{A_2}{j}\subst{A_3}{j'} & = A_1\subst{A_3}{j'}\subst{A_2}{j} & j, j' & \in J_1 \\
	\mpar{A_1\subst{A_2}{j_1}}\subst{A_3}{j_2} & = A_1\subst{A_2\subst{A_3}{j_2}}{j_1} & \mpar{j_1, j_2} & \in J_1 \times J_2
\end{align*}
Where the equality is modulo isomorphism (state renaming, associativity, commutativity).
\end{prop}
This property is induced by the composition on open pNets.
Intuitively it holds because the cartesian product of states, the union of sets, the union of maps and the conjunction on formulas (in the guards) are commutative and associative.
This allows us to define the simultaneous composition \(A\mdbrk{A_j^{j \in J'}}\) as the result of any order of (sequential) composition where each \(A_j\) is composed in the hole \(j\).
Even if an automaton is composed in two distinct holes it does not share its variables, each composition makes the cartesian product of states and a disjoint union of the variables.
In practise, variables may have to be renamed.


\section{Properties of a refinement relation for Open Automata}\label{sec:proofelts}
There are several properties we may expect from a refinement relation.
Depending on these properties, different kinds of refinement can be used.
For example if we are interested in producing the same sequences of actions as another automaton we may want to use trace set inclusion as a refinement.
Here the main expected properties are related to composition and action refinement. % LATER: explain action refinement here or remove if not tackled
Because of composition, a relation as strong as simulation must be used.

Informally, a simulation relating two automata means that every run of one automaton can be simulated by the other.
Simulations are defined by relating states of automata.
Two classical automata are called in simulation if there is a simulation relating their states.

Note that in the previous paragraph there are two relations:
The first is between states of two specific automata (\(R \subseteq S_1 \times S_2\)), the second is between automata (\(A_1 \leq A_2\)).
Generally the second is implicit because its definition is always \(\exists R \subseteq S_1 \times S_2, P\mpar{R}\) with \(P\) a property, and only talking about \(R\) and \(P\) is sufficient.
However later on in this article we will define more complex relations on automata so we clarify the distinction now.
A relation of second kind will be called ``relation on automata" whereas a relation of the first kind is called ``relation on configurations" as defined below.
In the work on FH-bisimulation \cite{henrio:01055091} such a relation \(R\) was defined as triples in \(S_1 \times S_2 \times \formulas\) where for \(\mpar{s_1, s_2} \in S_1 \times S_2\) there is a unique \(f \in \formulas\) such that \(\mpar{s_1, s_2, f} \in R\).
This is classically the definition of a function from \(S_1 \times S_2\) to \(\formulas\) so we will define it as such.
\begin{defi}[Relation on configurations]
A relation on configurations of two open automata \(\OAg[1]\) and \(\OAg[2]\) is a function \(R: S_1 \times S_2 \to \rformulas[V_1 \uplus V_2]\).

Two states \(s_1 \in S_1, s_2 \in S_2\) with their respective valuations \(\sigma_1: V_1 \to \values, \sigma_2: V_2 \to \values\) are related iff \(\sigma_1 \uplus \sigma_2 \vdash R\mpar{s_1, s_2}\).
\end{defi}
The important properties we consider for the relation on automata are:
\begin{defi} A relation on open automata \(\leq\) is
\defitem \textbf{reflexive} iff \(\forall a, a \leq a\);
\defitem \textbf{transitive} iff \(\forall a\, b\, c, a \leq b \wedge b \leq c \implies a \leq c\);
\defitem \textbf{a preorder} iff it is reflexive and transitive;
\defitem \textbf{correct w.r.t.\@ composition} iff \(\forall a\, b, a\subst{b}{j} \leq a\);
\defitem \textbf{complete w.r.t.\@ composition} iff \(\forall a\, b, a \leq b \implies \exists c, a \cong b\subst{c}{j}\);
\defitem \textbf{context refining for composition} iff \(\forall a\, b\, c, a \leq b \implies a\subst{c}{j} \leq b\subst{c}{j}\);
\defitem \textbf{congruent for composition} iff \(\forall a\, b\, c, a \leq b \implies c\subst{a}{j} \leq c\subst{b}{j}\);
\defitem \textbf{compatible with composition} iff \(\forall a\, b\, c\, d, a \leq b \wedge c \leq d \implies c\subst{a}{j} \leq d\subst{b}{j}\);
\defitem \textbf{compatible with FH-bisimulation} iff \(\forall a\, b\, c, d, a \cong b \wedge c \cong d \wedge a \leq c \implies b \leq d\).
\end{defi}
Reflexivity, transitivity and preorder are classical properties on relations.
Correctness w.r.t.\@ composition means that every composition is considered a refinement.
This property captures the expected behaviour of a refinement relation on a compositionnal structure like the open automata.
Completeness w.r.t.\@ composition means that a refinement corresponds to the left automaton being equivalent to some composition of the right automaton.
This property is useful if we want to characterise the kind of operations that can generate any refined automaton starting from the specification.
We won't have it because extending the domain of the initial valuation will be a refinement which can't be expressed with composition.
Yet a ``completeness w.r.t.\@ some set of operations" is still a strong and interesting property.
Context refinement is the refinement being compatible with composition of the same automaton.
Congruence is the refinement being compatible with being composed in the same automaton.
Compatibility with composition is the conjunction of the two latter (assuming the relation is a preorder).
This property is required on compositionnal structures to be of any use in verification, proofs and for model checking.
Finally compatibility with FH-bisimulation is the refinement not being able to distinguish two FH-bisimilar automata.
Since FH-bisimulation is the pre-existing equivalence relation, we should not introduce an incompatible proof strategy.

The important properties we consider for the relation on states are being a simulation and the prevention of deadlocks as defined in the following definitions.
\begin{defi}[Pre-simulation]
For two open automata \(A_1 \defobject \OAg[1]\) and \(A_2 \defobject \OAg[2]\), a relation on configurations \(R: S_1 \times S_2 \to \rformulas[V_1 \uplus V_2]\) is a pre-simulation if it satisfies both
\defitem Initial configurations are related: \(\sigma_{01} \uplus \sigma_{02} \vdash R\mpar{s_{01}, s_{02}}\);
\defitem From related states, all out-transitions from \(A_1\) can be simulated in \(A_2\) and their target states are related:
\begin{multline*}
	\forall \mpar{s_1, s_2} \in S_1 \times S_2, \bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \forall \sigma: V_1 \uplus V_2 \uplus \fvars{t_1} \to \values, \\
	\mpar{\sigma \vdash R\mpar{s_1, s_2} \wedge g_1} \implies \bigsymb{\exists} t_2 \defobject \OTx{2}{}{2}{2} \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \\
	\sigma \uplus \nu \vdash \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge g_2 \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2}
\end{multline*}
\end{defi}
This definition translated to open automata the classical definition of simulation \marginpar{cite: Fernandez-Mounier-91-b}.
The last formula means that for every pair of related configurations of the automaton and every possible transitions (\(\vdash g_1\)) from the first automaton, there is a possible transition (\(\vdash g_2\)) such that the produced action matches (\(\alpha_1 = \alpha_2\)), the same holes' action (\(J'_1 \cap J'_2\)) matches (\(\beta_{1j} = \beta_{2j}\)) and the target states are related after variable update. % OR variableS
Apart from holes, this is a natural extension of the notion of simulation on LTS, which is the same definition without variables nor holes nor guards.
In FH-bisimulation, holes with the same name will receive the same open automaton when composed, and the resulting open automaton will still be equivalent.
Here we assume that one of the related open automata can be obtained by composing an open automaton in a hole, open automaton which can have holes itself.
This implies that there is no relation between their holes, for instance composing \(A_i\) in \(j_i\) (\(1 \leq i \leq n\)) of \(A_0\) gives the set of holes \(J \defobject \mpar{\biguplus_{0 \leq i \leq n} J_i} \setminus \mset{j_i}{1 \leq i \leq n}\) that is neither subset nor superset of \(J_0\).
Yet we still assume that in holes with the same name, the same open automaton will be composed.
Hence only the holes in common have to match their actions.
However it is not sufficient to imply properties on the relation on automatons like being a preorder.
It is only a necessary condition for any relation that will be defined with ``simulation" in its name.

Deadlocks are reachable configurations from which no further transition is possible.
They can arise unpredictably when parallelism is involved (which is the case in our composition) and they break the intended behaviour of a system.
By preventing them we could hope that the refinement preserves some liveness properties.
\begin{defi}[Deadlock prevention, intuitive definition]
A relation on configurations \(R: S_1 \times S_2 \to \rformulas[V_1 \uplus V_2]\) is deadlock reducing if:
\defitem It is a pre-simulation;
\defitem If from related states, there is a possible transition in the specification, then there is a pair of matching transition:
\begin{multline*}
	\forall \mpar{s_1, s_2} \in S_1 \times S_2, \forall \sigma: V_1 \uplus V_2 \to \values, \mpar{\sigma \vdash R\mpar{s_1, s_2}} \implies \\
	\mpar{\exists t_2 \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \sigma \uplus \nu \vdash \fguard{t_2}} \implies \\
	\bigsymb{\exists} \mpar{t_1, t_2} \defobject \mpar{\OTx{1}{}{1}{1}, \OTx{2}{}{2}{2}} \in \fOT{s_1} \times \fOT{s_2}, \exists \nu: \fvars{t_1} \uplus \fvars{t_2} \to \values, \\
	\sigma \uplus \nu \vdash g_1 \wedge g_2 \wedge \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2}
\end{multline*}
\end{defi}
Actually, this requirement prevents the presence of deadlock state in the first automaton if there is a related non-deadlock state in the second by contraposition.
On top of that the transition preventing the deadlock has to be an existing transition in the specification.
This is because a valid transition unmatched in the specification is not a deadlock, yet we do not want it.
The direct formulation of the property would also have required the unintuitive quantification on a possibly empty set of transition to state that they are impossible.
The two previous reasons motivated the formulation in contraposed form.

``Deadlock prevention" conflicts with all the properties where composition is involved (for instance ``composition correctness") by disallowing some unwanted cases where an automaton in a hole cannot produce any action that any out-transition expects.
In particular filling a hole with the deadlock automaton (only one state without out-transitions) is not considered a refinement for a deadlock reducing relation.
A way to solve these conflicts is to characterise a composition that do not introduce deadlocks, which will be used instead of the composition introduced earlier.
\begin{defi}[Reachability]
For any open automata \(A \defobject \OAg\), a reachability predicate \(\reach{A}: S \to \rformulas[V]\) is a predicate on states satisfying both
\defitem Inital state is reachable: \(\sigma_0 \vdash \reach{A}\mpar{s_0}\)
\defitem Reachability is preserved across transitions: \nmm{\bigsymb{\forall} t \defobject \OTg \in T, \fvars{t} \vdash \reach{A}\mpar{s} \wedge g \implies \reach{A}\mpar{s'}\psubst{\psi}}
\end{defi}
The reachability predicate is used to characterise the reachable configurations in a run of an automaton.
In fact the role of the predicate is to characterise potentially reachable configurations without having to characterise configurations as the result of a valid path in an automaton.

To do that we impose that the initial configuration is reachable and that reachability is preserved by taking valid transitions.
This effectively makes reachability take into account all paths, and potentially over-approximate the reachable configurations.
The exact reachability may not be representable in the formulas, hence the need of potentially over-approximating.

% Another way of understanding this predicate is that it is a fixpoint of the union of valuations (function \(f\) defined below) that contains the initial valuation:
% \begin{align*}
	% f\mpar{p} = \mbrc{\mbox{\nmm{s' \mapsto p\mpar{s'} \vee \bigsymb{\bigvee_\subbox{\OTg \,\in\, \fIT{s'}}} p\mpar{s}\psubst{\psi} \wedge g}}} && % TODO: fix that in some way
	% \sigma_0 \vdash \reach{A}\mpar{s_0} &&
	% f\mpar{\reach{A}} = \reach{A}
% \end{align*}
\begin{defi}[Non-locking composition, intuitive definition]
Let \(A_c \defobject \OAg[c]\), \(A_p \defobject \OAg[p]\) and \(j \in J_p\).
The composition \(A \defobject A_p\subst{A_c}{j}\) is non-locking if \(A\) has a reachability predicate satisfying:
From reachable configurations, if there was a possible transition in \(A_p\) then there is a possible transition in \(A_p\subst{A_c}{j}\).

Formally for \(A = \OAg\), it gives
\begin{multline*}
	\forall s \defobject \mpar{s_p, s_c} \in S, \forall \sigma: V \to \values, \mpar{\sigma \vdash \reach{A_p\subst{A_c}{j}}\mpar{s}} \implies \\
	\mpar{\exists t_p \in \fOT{s_p}, \exists \nu_p: \fvars{t_p} \to \values, \sigma \uplus \nu_p \vdash \fguard{t_p}} \implies \\
	\exists t \in \fOT{s}, \exists \nu: \fvars{t} \to \values, \sigma \uplus \nu \vdash \fguard{t}
\end{multline*}
\end{defi}
We can expand the aliases \(S, V\) into \(S_p \times S_c, V_p \uplus V_c\) and transform the last transition \(t\) into a pair \(\mpar{t_p, t}\) where the first transition is the one from \(A_p\) which generated \(t\).
Doing that makes the definition become mildly similar with the deadlock prevention one. % OR slightly
It is not a coincidence because their goal is to caracterise the same kind of compatibility between automata.
Actually it is possible to simplify both definition and make them even more similar.
\begin{defi}[Deadlock prevention, working definition]
A relation on configurations \(R: S_1 \times S_2 \to \rformulas[V_1 \uplus V_2]\) is deadlock reducing if it is a pre-simulation and it satisfies the following:
\[ \forall \mpar{s_1, s_2} \in S_1 \times S_2, V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \vdash R\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \]
\end{defi}
The requirement here is that from any related configurations, if there is a possible transition in the second automaton (whatever the value of the free variables) then there is a possible transition in the first automaton (the existential quantifier is implicit in the notation \(\vdash\)).
The transition are not matched because the relation on configurations is a pre-simulation and it is sufficient to ensure it as will be shown in the proof.
Apart from the matching transitions this is exactly the same explaination as the intuitive definition.
The expected advantage of this formulation is that a SMT should behave better without the quantifiers.
Indeed the big disjunctions are not quantifiers because in practise the out-transitions are finitary, and so is the expansion of the disjunction. % Check if that construction is correct
\begin{lem}
The intuitive and working definition of deadlock prevention are equivalent.
\end{lem}
\begin{defi}[Non-locking composition, working definition]
The composition \(A \defobject A_p\subst{A_c}{j}\) is a non-locking composition if:
\[ \forall s \defobject \mpar{s_p, s_c} \in S, V \uplus \biguplus_\subbox{t_p \in \fOT{s_p}} \fvars{t_p} \vdash \reach{A}\mpar{s} \wedge \bigvee_\subbox{t_p \in \fOT{s_p}} \fguard{t_p} \implies \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \]
\end{defi}
\begin{lem}
The intuitive and working definition of non-locking composition are equivalent.
\end{lem}
An illustration of both the introduction of a deadlock by composition and the definition of non-locking composition is given in Appendix \ref{apx:lockcomp}.
Proof of both lemma are given in Appendix \ref{apx:lemeqd}.

This new definition of composition can replace the standard composition in the case where only one hole is filled, and also be extended to a simultaneous composition.
For the simultaneous composition, we may think that if the last composition of a specific composition order is non-locking, then every composition is non-locking for all composition order. % orderS
Unfortunately it is not true.
Actually even if the last composition of any order of composition is non-locking there is no guarantee that this order is non-locking at each intermediate step.
However the opposite way is true even if uninformative:
If there is an order of composition where every composition is non-locking then the last composition is non-locking, last composition resulting in the same automaton as the simultaneous composition.
So the condition is better checked after the simultaneous composition or the last individual composition.
\begin{exi}
\begin{figure}
\centering
\input{file_sync.tex}
\caption{A made-up protocol for file synchronisation}
\label{fig:pnls}
\end{figure}
The automaton on Figure \ref{fig:pnls} is a sample protocol for file synchronisation.
The two holes are \(net\) a process to manage network communications, and \(hash\) a process to check files integrity.
The state \(i\) is the initial state.
In that state we want to synchronise the files before working, or work on the local version as a fallback.
If the preferred version is the remote one, we go in state \(d1\) asking the netwotk manager to fetch the lastest version, then ask the integrity checker to validate the files.
If the preferred version is the local one, we go in state \(d2\) asking for the integrity checker to validate the local files, then ask the network manager to push them.
In fallback we use the local version.

We can plug an inactive process for the network manager and the file integrity checker by composing a deadlock automaton in their holes, but always both at the same time.
The reason for that is the simultaneous composition is non-locking, but any individual composition is locking because the state \(d1\) or \(d2\) (depending on the order) becomes a deadlock.
\end{exi}
From this point and in the previous definitions, composition will only refer to non-locking composition.

A relation on open automata and its corresponding relation on configurations are simulations if the latter is a deadlock reducing pre-simulations and the former is a preorder.
With all these properties we can now look at some concrete refinement relations.


\section{Refinement relations in restricted cases}\label{sec:prelref}
The main goal of this section is to explain the different aspects of refinement in restricted cases so that they are not all introduced at once in the real refinement relation.
In particular if we have a family of open automata \(A_i \defobject \OAg[i]\), \(0 \leq i \leq n\), let \(A \defobject \OAg\) be such that \(A = A_0\mdbrk{j_i \mapsto A_i \middle| 1 \leq i \leq n}\).
Recall that there is no relation between the holes of \(A\) and \(A_0\) because \(J = \mpar{\biguplus_{0 \leq i \leq n} J_i} \setminus \mset{j_i}{1 \leq i \leq n}\) is neither subset nor superset of \(J_0\).
So looking at restricted cases where holes are related in a specific manner can help understanding the general case.
Hopefully the intermediate refinement relation introduced can be used as simpler (and less expensive to compute) versions of the real refinement relation in the case the manipulated automata respect some constraints.

We restrict the holes of the related automata so that we can explain the different refinements without their interactions.
In the following definition, \(\triangle \in \mbrc{\subseteq, =, \supseteq}\).
\begin{defi}[Hole-\(\triangle\) simulation]
For two open automata \(A_1 \defobject \OAg[1]\) and \(A_2 \defobject \OAg[2]\), the relation on configurations \(R: S_1 \times S_2 \to \rformulas[V_1 \uplus V_2]\) is a hole-\(\triangle\) simulation of \(A_1\) by \(A_2\) if:
\item[1)] \(J_1 \triangle J_2\)
\item[2)] \(\sigma_{01} \uplus \sigma_{02} \vdash R\mpar{s_{01}, s_{02}}\)
\item[3)] \(\forall \mpar{s_1, s_2} \in S_1 \times S_2,\)\vspace{-8pt}
\noindent\begin{multline*}
	\mpar{\everymath{\displaystyle}\begin{array}{l}
		\bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \bigsymb{\exists} \mpar{t_{2x} \defobject \OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X}, \\
		\quad \mpar{\forall x \in X, J'_{2x} \cap J_1 = J'_1 \cap J_2} \\[-10pt]
		\nwedge V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\begin{array}{l}
			\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \\[12pt]
			\nwedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
		\end{array}}
	\end{array}} \\
	\wedge \mpar{V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \vdash R\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1}}
\end{multline*}
\end{defi}
The third item of the definition has two parts:
The first part is the main requirement, a (not proved equivalent) reordering of the pre-simulation requirement so that it better fits SMT.
Instead of matching an effective transition to another effective transition as in the pre-simulation definition, we match an open transition to a family of covering open-transitions.
The second part is directly the deadlock prevention requirement.

The hole-equal simulation is applicable when the related automata have the same holes.
It is designed to capture all the refinements other than composition: Duplicating and merging states and transitions, changing variables, removing transitions, adding requirements to guards, specifying more inital variables, and many more.

The hole-subset simulation is applicable when the simulated automaton has less holes.
It is designed to have composition correctness when the composed automata have no holes.

The hole-superset simulation is applicable when the simulated automaton has more holes.
It is designed to capture the addition of holes involved in transitions, which will indirectly add requirements to transitions when the new holes will be composed.
It is also an attempt at giving a meaning to the new holes when composing with any open automata.
However it does not capture the removal of holes because other issues arise when trying to both add and remove holes.

Examples of application of the different refinement relations are given in Appendix \ref{apx:refrel}.
\begin{thm} A hole-\(\triangle\) simulation is a pre-simulation. \end{thm}
Proof is given in Appendix \ref{apx:presim}.
\begin{thm} The hole-\(\triangle\) simulation on automata is a preorder. \end{thm}
The idea for reflexivity is that the related automata are always in the same configuration.
\[ R \defobject \mpar{s, s'} \mapsto \choice{\bigwedge_{v \in V} v_1 = v_2 & \text{if } s = s'\\ \bot & \text{otherwise}} \]
Where \(v_x\) is the renaming to distinguish conflicting automaton variables.
\(R\) is a witness of the reflexivity, the proof is mainly the same as several of the following ones so it will be omitted.

For three open automata \(A_1 \defobject \OAg[1]\), \(A_2 \defobject \OAg[2]\) and \(A_3 \defobject \OAg[3]\), such that \(R_{12}\) is a hole-\(\triangle\) simulation of \(A_1\) by \(A_2\) and \(R_{23}\) of \(A_2\) by \(A_3\), we want to define \(R\) by saying that there exists a state \(s_2 \in S_2\) and values for \(V_2\) such that \(R_{12}\mpar{s_1, s_2} \wedge R_{23}\mpar{s_2, s_3}\).
However we cannot talk about states in formulas.
The solution is to expand the existential quantifier on states as we did in deadlock prevention, which is possible because states are finite.
\[ R \defobject \mpar{s_1, s_3} \mapsto \exists V_2, \bigvee_\subbox{s_2 \in S_2} R_{12}\mpar{s_1, s_2} \wedge R_{23}\mpar{s_2, s_3} \]
\(R\) is a witness of the transitivity, proof is given in Appendix \ref{apx:trans}.
\begin{thm}[Context refinement] Hole-equal simulation is context refining. \end{thm}
For three open automata \(A_1 \defobject \OAg[1]\), \(A_2 \defobject \OAg[2]\) and \(A_3 \defobject \OAg[3]\) with \(J_1 = J_2\), let \(k \in J_1\).
Let \(R_{12}\) be a hole-equal simulation of \(A_1\) by \(A_2\) and \(\reach{A\subst{A_3}{k}}\) be a witness that \(A\subst{A_3}{k}\) is non-locking.
The idea for the relation on configurations is that \(A_2\) simulates \(A_1\) while \(A_3\) does the same things in both compositions in the hole \(k\).
\[ R \defobject \mpar{\mpar{s_1, s_{31}}, \mpar{s_2, s_{32}}} \mapsto \choice{R_{12}\mpar{s_1, s_2} \wedge \reach{A_{13}}\mpar{s_1, s_{31}} \wedge \bigwedge_\subbox{v_3 \in V_3} v_{31} = v_{32} & \text{if } s_{31} = s_{32} \\ \bot & \text{otherwise}} \]
Where \(y_{3x}\) is the renaming of \(y_3\) from \(A_3\) in \(A_x\subst{A_3}{k}\).
\(R\) is a witness of the context refinement.
\begin{prop}[Limited composition correctness]\label{prop:cc'} Hole-subset simulation is correct w.r.t.\@ composition with automata without holes. \end{prop}
For two open automata \(A_1 \defobject \OAg[1]\) and \(A_2 \defobject \OAg[2]\) with \(J_2 = \emptyset\), let \(k \in J_1\) and \(A \defobject A_1\subst{A_2}{k}\).
Let \(\reach{A}\) be a witness that \(A\) is non-locking.
The idea for the relation on configurations is that the copy of \(A_1\) in \(A\) do the same things as \(A_1\), as if we were trying to prove reflexivity.
\[ R \defobject \mpar{\mpar{s_{1'}, s_2}, s_1} \mapsto \choice{\reach{A}\mpar{s_{1'}, s_2} \wedge \bigwedge_\subbox{v_1 \in V_1} v_{1'} = v_1 & \text{if } s_{1'} = s_1 \\ \bot & \text{otherwise}} \]
Where \(y_{1'}\) is the renaming of \(y_1\) from \(A_1\) in \(A\).
\(R\) is a witness of the limited composition correctness.
\begin{prop}[Special composition correctness]
For three open automata \(A_1 \defobject \OAg[1]\), \(A_2 \defobject \OAg[2]\) and \(A_3 \defobject \OAg[3]\), let \(k \in J_1 \setminus J_2\) and \(R_{12}\) be a hole-superset simulation of \(A_1\) by \(A_2\).
There is a hole-superset simulation of \(A_1\subst{A_3}{k}\) by \(A_2\).
\end{prop}
Let \(\reach{A_1\subst{A_3}{k}}\) be a witness that \(A_1\subst{A_3}{k}\) is non-locking.
The idea for the relation on configurations is to combine the non-locking composition and the already existing realtion on configurations.
\[ R \defobject \mpar{\mpar{s_1, s_3}, s_2} \mapsto R_{12}\mpar{s_1, s_2} \wedge \reach{A_1\subst{A_3}{k}}\mpar{s_1, s_3} \]
\(R\) is a witness of the secial composition correctness.
Proofs of the above theorem and propositions are given in Appendix \ref{apx:ophts}.

% J'2 \subseteq J'1 in hole-subset, J'1 \subseteq J'2 in hole-superset (decide of transition variable with holes); composition with new holes is hole-subset where hole variables are free then hole-superset where hole names have no conflicts with removed holes. Transitivity must ensure holes name have no conflict for that reason!


% Mettre des sets de noms en commun qu'on veut effectivement mapper pour la transitivité
% Explain what happens on holes constraints and action constraints
% refinement can be used to specify behaviour/constraints on holes (like an API: first do anything not involving the api, then initialise the api, then do whatever you want that do not unload the api, then unload the api by returning to the first state), then have a relation for every hole with a different automata and this means well behaving with respect to the environement (holes)
\section{Refinement relation for open automata}\label{sec:refinement}
\begin{defi}[Open automata refinement]
For two open automata \(A_1 \defobject \OA{S_1}{s_{01}}{J_1}{V_1}{\sigma_{01}}{T_1}\) and \(A_2 \defobject \OA{S_2}{s_{02}}{J_2}{V_2}{\sigma_{02}}{T_2}\), \(A_1\) is a refinement of \(A_2\) looking at \(H\), noted \(\wrel{A_1}{A_2}{H}\), with \(H \subseteq J_1 \cap J_2\), is defined as:
\begin{multline*}
	\exists R: \mpar{S_1 \times S_2} \to \rformulas[V_1 \uplus V_2], \mpar{\sigma_{01} \uplus \sigma_{02} \vdash R\mpar{s_{01}, s_{02}}} \wedge \forall \mpar{s_1, s_2} \in S_1 \times S_2, \\
	\mpar{\everymath{\displaystyle}\begin{array}{l}
		\bigsymb{\forall} \OTx{1}{}{1}{1} \in \fOT{s_1}, \bigsymb{\exists} \mpar{\OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X}, \\[12pt]
		\quad \mpar{\forall x \in X, J'_{2x} \cap J_1 \cap H = J'_1 \cap J_2 \cap H} \\[-10pt]
		\nwedge V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\begin{array}{l}
			\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2 \cap H} \beta_{1j} = \beta_{2xj} \\
			\nwedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
		\end{array}} \\
	\end{array}} \\
	\wedge V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \vdash R\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1}
\end{multline*}
\end{defi}
% refinement relation definition
% Explain definition, really needed
% safety is no longer trivial, prove the safety
% Prove all expected properties except pre-simulation

% What happens on untracked holes (untracked holes equivalent behaviour => free variables; some sort of daisy equivalence)
% Yet having untracked holes is interesting because we can be a refinement of several OA, each on different holes.

\section{Future work}
% TODO: Weak variants, tau-stuttering, livelocks
% Other kind of refinement relation that \Quentin{I may explore}{This is a note for possible path, some may be explored, some may not.} are control refinement/hole refinement\footnote{No good formulation atm, the idea is that \(a \leq b \defnotation sth \wedge J_a \setminus J_b \leq_{ctrl} J_b \setminus J_a\), sth is probably a clause to ensure that they behave the same without holes involved.}, (meet semi)lattice refinement\footnote{meet = handshake, \(a \leq b \defnotation a = a || b\) with sync holes, I think this will be equivalent to hole-identical sim, (join=non-det choice?)}, weak-simulation refinement\footnote{Weak variation for each interesting simulation refinement}, composition-correct refinement\footnote{Basically a stricter variant of simulation-refinement where simulation has to take place the other way for some transitions (no different holes?) in order to be correct wrt composition}.

\section{Conclusion}


\pagebreak
\bibliographystyle{plain}
\bibliography{biblio}

\pagebreak
\appendix
\part*{Appendix}

\section{Example of composition}

\subsection{Complete composition}\label{apx:composition}
\begin{figure}[h]
\centering
\input{Traffic_Lights_Spec.tex}
\caption{The specification of a traffic light system}
\label{fig:tls}
\end{figure}
\begin{figure}
\centering
\input{Traffic_Lights_Controller.tex}
\vrule
\input{Traffic_Lights_Register.tex}
\caption{On the left: An example of controller agent; On the right: An example of counter agent}
\label{fig:tlh}
\end{figure}
This example is derived and adapted from a traffic light controller in a collection of examples for pNets.
It is supposed to be a single traffic light.

Figure \ref{fig:tls} shows the light controller with some synchronisation logic.
It  takes an unimplemented control circuit in the hole \(ctl\) which gives the timings and an also unimplemented counter in the hole \(cnt\) to count external \(\act{tick}\) actions.
The three states are used to remember which colored light is on and this color can be retrieved by the environment by synchronising with the actions \(\act{onXxx}\) (Xxx is either Red, Yellow or Green) if it is not stored externally.

The color switches when the counter and the control circuit agree that the time is over.
The new time limit can be set by the control circuit and the exposed action to the exterior is a \(\tau\).

The components we choose to compose in the holes are in Figure \ref{fig:tlh}.
On the left there is the controller agent which will be composed in the hole \(ctl\).
Its role is to decide the duration before switching the lights.
This implementation is simply a constant time for each color; we could imagine using a more fancy controller which decides of the time depending on the traffic of each lane.

On the right is the counter agent which will be composed in the hole \(cnt\).
Its role is to get a target, then count ticks until that target is reached, then emit an action with the elapsed time and restart.
This implementation does exactly that and forbids any extra tick.

\begin{figure}
\centering
\input{Traffic_Lights_Full.tex}
\caption{The full traffic lights system}
\label{fig:tlf}
\end{figure}
The automaton on Figure \ref{fig:tlf} is a simplification of the composition of the specification on Figure \ref{fig:tls} and the agents on Figure \ref{fig:tlh}.
The simplification was hand made because it is a hard problem as explained at the end of Section \ref{sec:comp}.
It consisted in removing unreachable states, reducing the size of the guard and reducing the amount of variables.
Otherwise the figure would have 36 states (\(3 \times 2 \times 6\)) but only 6 reachable from the initial configuration.
The simplified transitions are the following (where \(n, n+1\) stands for numbers between 1 and 6, Xxx is either Red, Yellow or Green and \(\mpar{Y, X}\) is accordingly \(\mpar{Y, R}\), \(\mpar{R, G}\) or \(\mpar{G, Y}\)):
\begin{itemize}
\item \nmm{\OT{XnS}{X(n+1)C}{\tau}{\mbrc{}}{\top}{\mbrc{t \gets k, c \gets 0}}} which is the composition of \nmm{\OT{X}{X}{\tau}{\mbrc{ctl \mapsto \theta\mpar{x}, cnt \mapsto \act{set}\mpar{x}}}{\top}{\mbrc{}}} from the specification with \nmm{\OT{S}{C}{\act{set}\mpar{x}}{\mbrc{}}{\top}{\mbrc{t \gets x, c \gets 0}}} from the counter and \nmm{\OT{n}{n+1}{\theta\mpar{k}}{\mbrc{}}{\top}{\mbrc{}}} from the controller.
\item \nmm{\OT{XnC}{XnC}{\act{tick}}{\mbrc{}}{c < t}{\mbrc{c \gets c + 1}}} which is the composition of \nmm{\OT{X}{X}{\act{tick}}{\mbrc{cnt \mapsto \act{tick}}}{\top}{\mbrc{}}} from the specification with \nmm{\OT{C}{C}{\act{tick}}{\mbrc{}}{c < t}{\mbrc{c \gets c + 1}}} from the counter.
\item \nmm{\OT{YnC}{X(n+1)S}{\act{TurnXxx}}{\mbrc{}}{c = t}{\mbrc{}}} which is the composition of \nmm{\OT{Y}{X}{\act{TurnXxx}}{\mbrc{cnt \mapsto \act{over}\mpar{x}, ctl \mapsto \delta\mpar{x}}}{\top}{\mbrc{}}} from the specification with \nmm{\OT{C}{S}{\act{over}\mpar{c}}{\mbrc{}}{c = t}{\mbrc{}}} from the counter and \nmm{\OT{n}{n+1}{\delta\mpar{x}}{\mbrc{}}{\top}{\mbrc{}}} from the controller.
\end{itemize}

To illustrate composition, hand made simplifications and value passing, the \(\tau\) transition from the state \(R\) will be examined.
The transition in the specification is \nmm{\OT{R}{R}{\tau}{\mbrc{cnt \mapsto \act{set}\mpar{x}, ctl \mapsto \theta\mpar{x}}}{\top}{\mbrc{}}}.
The composition can produce 12 states containing the \(R\) state, these states are in \(\mbrc{R} \times \mdbrk{1; 6} \times \mbrc{S, C}\), however only \(R1S\) and \(R2C\) are reachable so we will only consider \(\tau\) transitions from these two.
The holes \(cnt\) and \(ctl\) are both involved in the \(\tau\) transition and filled with automata so the composed automata must synchronise with a transition.

In the state \(R2C\) the composition produces 2 transitions by composition out of the \(\tau\) transition but both have a false guard; It is still interesting to look at one of them to show the product of composition without simplification.

\nmm{\OT{R2C}{R3C}{\tau}{\mbrc{}}{\top \wedge \top \wedge c < t \wedge \act{set}\mpar{x} = \act{tick} \wedge \theta\mpar{x} = \delta\mpar{x_C}}{\mbrc{c \gets c + 1}}} is made with \nmm{\OT{2}{3}{\delta\mpar{x}}{\mbrc{}}{\top}{\mbrc{}}} from the controller and \nmm{\OT{C}{C}{\act{tick}}{\mbrc{}}{c < t}{\mbrc{c \gets c + 1}}} from the counter.
Obviously the equality of actions in the guard cannot be satisfied so the guard is false, it is equivalent to have no transition.
We could go on to another transition but something worth explaining happened to build its guard.
The first two \(\top\) come from the guards of the specification and the controller.
\(c < t\) comes from the counter.
The rest of the guard comes from the equality constraint between holes actions and automata actions.
When composing this expression, we can see that the \(x\) variables from the specification, the controller and the counter are in conflict.
To resolve the conflict, the conflicted variables were renamed depending on where they come from.

In the state \(R1S\) the composition produces 1 transition out of the \(\tau\) transition.
The simplified transition follows the first pattern in the transitions described before.
Examining the composition process can illustrate how value passing work.
The obtained guard is \(\top \wedge \top \wedge \top \wedge \theta\mpar{x} = \theta\mpar{17} \wedge \act{set}\mpar{x} = \act{set}\mpar{x_R}\) and the obtained variable assignment is \(\mbrc{t \gets x_R, c \gets 0}\).
We can see how value passing works in the equality constraints: the only possible value of \(x\) and \(x_R\) making the guard hold is \(17\), this value has been synchronised from the controller to \(x\) then to the second occurrence of \(x\) to the distinct \(x\) of the counter.
Note that \nmm{\OT{S}{C}{\act{set}\mpar{t}}{\mbrc{}}{\top}{\mbrc{c \gets 0}}} wouldn't have worked as a transition for the controller because \(t\) is not a transition variable, its value is fixed before the transition and cannot be set outside of the variable update, hence the use of an auxiliary variable \(x\).

\subsection{Composition introducing deadlocks and requirements of non-locking composition}\label{apx:lockcomp}
\begin{exi}[Deadlocks introduced by composition]
This example reuses the counter introduced in Figure \ref{fig:tlh}.
The behaviour of the counter is to count external \(\act{tick}\) actions up to the amount set by action \(\act{set}\mpar{x}\) then to notify the environnement that this amount of time elapsed.
In the traffic light example the clock is not specified, we will introduce deadlocks using a wisely choosen clock specification.
However the full traffic light will not be used in order to simplify the example, only the counter will be.

\begin{figure}
\input{randomtick_clock.tex}
\vrule
\input{register_anytick.tex}
\caption{On the left: A clock which imposes a tick; On the right: A modified version of the counter at figure \ref{fig:tlh}}
\label{fig:anytick}
\end{figure}
The clock on the left side of Figure \ref{fig:anytick} transmit the actions of its hole unchanged until the clock imposes a \(\act{tick}\) on its hole.
This can model a physical clock, because physical time ticks cannot be delayed.

If the hole cannot handle a \(\act{tick}\) at any time then there is a deadlock, which is the case with our counter.
The composition of this clock with the counter is given on the left of Figure \ref{fig:deadlock}.
\begin{figure}
\input{Composition_deadlock.tex}
\vrule
\input{Composition_nolock.tex}
\caption{On the left: Deadlocks introduced by composition; On the right: No deadlock introduced by composition}
\label{fig:deadlock}
\end{figure}
There are two deadlocks:
The first is in the state \(1S\), which correspond to the clock trying to imppose a tick when the counter is not set.
The second is in the state \(1C\), which correspond to the clock trying to impose a tick when the counter has reached the amount peviously set, but not has not yet reported it to the environment.
These deadlocks could have been in the specification in which case they were intended, but it is not the case here.

The counter on the right of Figure \ref{fig:anytick} is a modification to accept ticks at in any state.
Composing this modified counter gives the automaton on the right of Figure \ref{fig:deadlock} which has no deadlocks.

We should successfully caracterise the second composition as non-locking but fail for the first.
\begin{itemize}
\item In the state \(0S\) any valuation is reachable (no initial valuation).
	In both automata the transition \nmm{\OT{0S}{1S}{\tau}{\mbrc{}}{\top}{\mbrc{}}} has a true guard, hence the first branch of the disjunction holds.
\item In the state \(0C\), for the left automaton, valuations where \(t \geq c \geq 0 \vee \mpar{t < 0 \wedge c = 0}\) are reachable; for the right automaton, valuations where \(c \geq 0\) are reachable.
	For all these valuations the transition \nmm{\OT{0C}{1C}{\tau}{\mbrc{}}{\top}{\mbrc{}}} has a true guard, hence the first branch of the disjunction holds.
\item In the state \(1C\), the same valuations as the ones reachable in \(0C\) are also reachable.
	In the right automaton the transition \nmm{\OT{1C}{0C}{\act{tick}}{\mbrc{}}{\top}{\mbrc{c \gets c + 1}}} has a true guard.
	In the left automaton the transition \nmm{\OT{1C}{0C}{\act{tick}}{\mbrc{}}{c < t}{\mbrc{c \gets c + 1}}} covers the cases where \(c < t\).
	For the other cases (\(c = t \vee t \leq 0 \mbrk{\leq c}\)) there are no transition with a true guard, and in the clock the transition same transition as for the state \(1S\) has a true guard, hence the composition is not non-locking.
\item In the state \(1S\) any valuation is reachable.
	In the left automaton, no transition is possible, and in the parent automaton \nmm{\OT{1}{0}{\act{tick}}{\mbrc{H \mapsto \act{tick}}}{\top}{\mbrc{}}} had a true guard, so the composition is not a non-locking composition (we already know it at this point).
	In the right automaton, \nmm{\OT{1S}{0S}{\act{tick}}{\mbrc{}}{\top}{\mbrc{}}} has a true guard.
\end{itemize}
The left automaton indeed fails at being the result of a non-locking composition where the right automaton passes.

One more thing worth noting is that for the left automaton, in the state \(1C\) with a valuation such that \(t < 0\), the counter agent is in a deadlock state.
We could have defined the non-locking composition so that this is considered as an intended deadlock, making the requirement symmetric.
However the the semantics of composition in a hole is asymmetric and the considered specification -as in the deadlock prevention- is the parent automaton.
\end{exi}


\section{Proof of equivalent definitions}\label{apx:lemeqd}

\subsection{Proof of lemma 1}
Let \(R\) be a pre-simulation between \(A_1 \defobject \OA{S_1}{s_{01}}{V_1}{\sigma_{01}}{J_1}{T_1}\) and \(A_2 \defobject \OA{S_2}{s_{02}}{V_2}{\sigma_{02}}{J_2}{T_2}\).
We want to prove:
\[ \forall \mpar{s_1, s_2} \in S_1 \times S_2, V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \vdash R\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \tag{WD}\label{eq:drWD} \]
\[ \bigsymb{\iff} \]
\begin{multline}
	\forall \mpar{s_1, s_2} \in S_1 \times S_2, \forall \sigma: V_1 \uplus V_2 \to \values, \mpar{\sigma \vdash R\mpar{s_1, s_2}} \implies \\
	\mpar{\exists t_2 \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \sigma \uplus \nu \vdash \fguard{t_2}} \implies \\
	\bigsymb{\exists} \mpar{t_1, t_2} \defobject \mpar{\OTx{1}{}{1}{1}, \OTx{2}{}{2}{2}} \in \fOT{s_1} \times \fOT{s_2}, \exists \nu: \fvars{t_1} \uplus \fvars{t_2} \to \values, \\
	\sigma \uplus \nu \vdash g_1 \wedge g_2 \wedge \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2}\tag{ID}\label{eq:drID}
\end{multline}
\begin{proof}
\item[\(\eqref{eq:drWD}\Rightarrow\eqref{eq:drID}\):]
	Let \(\mpar{s_1, s_2} \in S_1 \times S_2\) and \(\sigma: V_1 \uplus V_2 \to \values\) such that:
	\[ \sigma \vdash R\mpar{s_1, s_2} \hyp{1} \]
	We admit the left side of the second implication in \eqref{eq:drID}:
	\[ \exists t_2 \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \sigma \uplus \nu \vdash \fguard{t_2} \hyp{2} \]
	And get immediately a transition \(t_2 \in \fOT{s_2}\), a valuation \(\nu: \fvars{t_2} \to \values\) and the hypothesis:
	\[ \sigma \uplus \nu \vdash \fguard{t_2} \hyp{2'} \]
	\(R\) satisfies \eqref{eq:drWD} with the current value of \(\mpar{s_1, s_2}\) and \(\sigma \uplus \nu\) completed with dummy values for the other variables of \nmm{\biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2}} so we have:
	\[ \sigma \uplus \nu \vdash R\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \hyp{3} \]
	The \(\vdash\) hides an implicit \(\exists\) that we use to get values to the variables in \nmm{\biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1}} in a valuation \(\mu\).
	The left side of the implication is proved using \hyp{1} and \hyp{2'} for the branch \(t_2\) of the disjunction.
	The right side is a disjunction so there is a \(t_1 \in \fOT{s_1}\) such that:
	\[ \sigma \uplus \nu \uplus \mu \vdash \fguard{t_1} \hyp{3'} \]
	At this point we have a pair \(\mpar{t_1, t_2}\) so we may be tempted to use it to prove the goal:
	\begin{multline}
		\bigsymb{\exists} \OTx{2}{}{2}{2} \in \fOT{s_2}, \OTx{1}{}{1}{1} \in \fOT{s_1}, \\
		\sigma \vdash g_2 \wedge \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge g_1 \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2} \goal{1}
	\end{multline}
	However we cannot yet prove it because we don't know whether \(t_2\) and \(t_1\) match.
	In order to get a \(t_2\) matching \(t_1\) we will use the fact that \(R\) is a pre-simulation:
	\begin{multline}
		\forall \mpar{s_1, s_2} \in S_1 \times S_2, \bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \forall \sigma: V_1 \uplus V_2 \uplus \fvars{t_1} \to \values, \\
		\mpar{\sigma \vdash R\mpar{s_1, s_2} \wedge g_1} \implies \bigsymb{\exists} t_2 \defobject \OTx{2}{}{2}{2} \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \\
		\sigma \uplus \nu \vdash \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge g_2 \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2} \hyp{0}
	\end{multline}
	\hyp{0} with current value of \(\mpar{s_1, s_2}\), \(t_1\) and \(\sigma \uplus \mu\) as a valuation of \(V_1 \uplus V_2 \uplus \fvars{t_1}\) gives:
	\begin{multline}
		\mpar{\sigma \uplus \mu \vdash R\mpar{s_1, s_2} \wedge g_1} \implies \exists t_2 \defobject \OTx{2}{}{2}{} \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \\
		\sigma \uplus \mu \uplus \nu \vdash \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge g_2 \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2} \hyp{0'}
	\end{multline}
	The left part of the implication is \hyp{1} and \hyp{3'}, so we get \(t'_2 \in \fOT{s_2}\), \(\nu': \fvars{t_2} \to \values\) and:
	\[ \sigma \uplus \mu \uplus \nu' \vdash \alpha_1 = \alpha'_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J''_2} \beta_{1j} = \beta'_{2j} \wedge g'_2 \wedge R\mpar{s'_1, s''_2}\psubst{\psi_1 \uplus \psi'_2} \hyp{4} \]
	The witnesses for \goal{1} are \(t'_2\) and \(t_1\), and the rest is proved with a combination of \hyp{4} and \hyp{3'}.
\item[\(\eqref{eq:drWD}\Leftarrow\eqref{eq:drID}\):]
	Let \(\mpar{s_1, s_2} \in S_1 \times S_2\) and \nmm{\sigma: V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \to \values}.
	We want to prove:
	\[ \sigma \vdash R\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \goal{2} \]
	We can admit the left part of the implication in which the big disjunction gives us a \(t_2 \in \fOT{s_2}\) and:
	\begin{gather}
		\sigma \vdash R\mpar{s_1, s_2} \hyp{5} \\
		\sigma \vdash \fguard{t_2} \hyp{6}
	\end{gather}
	We are left to prove:
	\[ \sigma \vdash \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \goal{2'} \]
	To do that we use \eqref{eq:drID} with the current value of \(\mpar{s_1, s_2}\) and \(\sigma\), and prove the premisse of the implication with \hyp{5} to get:
	\begin{multline}
		\mpar{\exists t_2 \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \sigma \uplus \nu \vdash \fguard{t_2}} \implies \\
		\bigsymb{\exists} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, t_2 \defobject \OTx{2}{}{2}{2} \in \fOT{s_2}, \exists \nu: \fvars{t_1} \uplus \fvars{t_2} \to \values, \\
		\sigma \uplus \nu \vdash g_1 \wedge g_2 \wedge \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2} \hyp{7}
	\end{multline}
	The left part of the implication is proved for \(t_2\) and \(\sigma\) (for the values covered by \(\nu\)) with \hyp{6}.
	The right part gives \(t_1\), \(t'_2\) and \(\nu\) such that (only the interesting part of the conjunction has been extracted):
	\[ \sigma \uplus \nu \vdash \fguard{t_1} \hyp{8} \]
	Which proves \goal{2'} with the values of \(\nu\) for the variables of \(\fguard{t_1}\) and dummy values for the other guards.
\end{proof}

\subsection{Proof of lemma 2}
We want to prove
\[ \forall s \defobject \mpar{s_p, s_c} \in S, V \uplus \biguplus_\subbox{t_p \in \fOT{s_p}} \fvars{t_p} \vdash \reach{A}\mpar{s} \wedge \bigvee_\subbox{t_p \in \fOT{s_p}} \fguard{t_p} \implies \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \tag{WD}\label{eq:nlcWD} \]
\[ \bigsymb{\iff} \]
\begin{multline*}
	\forall s \defobject \mpar{s_p, s_c} \in S, \forall \sigma: V \to \values, \mpar{\sigma \vdash \reach{A}\mpar{s}} \implies \\
	\mpar{\exists t_p \in \fOT{s_p}, \exists \nu: \fvars{t_p} \to \values, \sigma \uplus \nu \vdash \fguard{t_p}} \implies \\
	\mpar{\exists t \in \fOT{s}, \exists \nu: \fvars{t} \to \values, \sigma \uplus \nu \vdash \fguard{t}} \tag{ID}\label{eq:nlcID}
\end{multline*}
\begin{proof}
\item[\(\eqref{eq:nlcWD}\Rightarrow\eqref{eq:nlcID}\):]
	Let \(s \defobject \mpar{s_p, s_c} \in S\) and \(\sigma \in V \to \values\) be such that:
	\[ \sigma \vdash \reach{A}\mpar{s} \hyp{1} \]
	We admit the left side of the second implication in \eqref{eq:nlcID}:
	\[ \exists t_p \in \fOT{s_p}, \exists \nu: \fvars{t_p} \to \values, \sigma \uplus \nu \vdash \fguard{t_p} \hyp{2} \]
	We get immediately a transition \(t_p \in \fOT{s_p}\), a valuation \(\nu: \fvars{t_p} \to \values\) and the hypothesis:
	\[ \sigma \uplus \nu \vdash \fguard{t_p} \hyp{2'} \]
	\(\reach{A}\) satisfies \eqref{eq:nlcWD} with the current value of \(s\) and \(\sigma \uplus \nu\) completed with dummy values for the other variables of \nmm{\biguplus_\subbox{t_p \in \fOT{s_p}} \fvars{t_p}} so we have:
	\[ \sigma \uplus \nu \vdash \reach{A}\mpar{s} \wedge \bigvee_\subbox{t_p \in \fOT{s_p}} \fguard{t_p} \implies \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \hyp{3} \]
	The \(\vdash\) hides an implicit \(\exists\) that we use to get \nmm{\mu: \biguplus_\subbox{t \in \fOT{s}} \fvars{t} \to \values}.
	The left side of the implication is proved using \hyp{1} and \hyp{2'} for the branch \(t_p\) of the disjunction.
	The right side is a big disjunction that gives us \(t \in \fOT{s}\) such that:
	\[ \sigma \uplus \nu \uplus \mu \vdash \fguard{t} \hyp{3'} \]
	At this point we have a \(t\) which is composed of a transition in \(A_p\) and one in \(A_c\) so unlike lemma 1 we do not need to check that two transitions matches.
	The current goal is:
	\[ \exists t \in \fOT{s}, \exists \nu: \fvars{t} \to \values, \sigma \uplus \nu \vdash \fguard{t} \]
	Which is proved on \(t\) with valuation \(\mu\) by \hyp{3'}.
\item[\(\eqref{eq:nlcWD}\Leftarrow\eqref{eq:nlcID}\):]
	Let \(s \defobject \mpar{s_p, s_c} \in S\), \nmm{\sigma: V \uplus \biguplus_\subbox{t_p \in \fOT{s_p}} \fvars{t_p} \to \values}.
	We want to prove:
	\[ \sigma \vdash \reach{A}\mpar{s} \wedge \bigvee_\subbox{t_p \in \fOT{s_p}} \fguard{t_p} \implies \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \goal{1} \]
	We can admit the left part of the implication in which the big disjunction gives us \(t_p \in \fOT{s_p}\) and:\\
	\begin{gather}
		\sigma \vdash \reach{A}\mpar{s} \hyp{4} \\
		\sigma \vdash \fguard{t_p} \hyp{5}
	\end{gather}
	We are left to prove:
	\[ \sigma \vdash \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \goal{1'} \]
	To do that we use \eqref{eq:nlcID} with the current value of \(s\) and \(\sigma\), and prove the premisse of the implication with \hyp{4} to get:
	\begin{multline}
		\mpar{\exists t_p \in \fOT{s_p}, \exists \nu: \fvars{t_p} \to \values, \sigma \uplus \nu \vdash \fguard{t_p}} \implies \\
		\exists t \in \fOT{s}, \exists \nu: \fvars{t} \to \values, \sigma \uplus \nu \vdash \fguard{t} \hyp{6}
	\end{multline}
	The left part of the implication is proved for \(t_p\) and \(\sigma\) (for the values covered by \(\nu\)) with \hyp{5}.
	The right part gives \(t\) and \(\nu\) such that:
	\[ \sigma \uplus \nu \vdash \fguard{t} \hyp{7} \]
	Which proves \goal{1'} with the values of \(\nu\) for the variables of \(\fguard{t}\) and dummy values for the other guards.
\end{proof}


\section{Examples of hole-\(\triangle\) simulations}\label{apx:refrel}

\subsection{Example of hole-equal simulation}
\begin{exi}
\begin{figure}
\centering
\input{parallel_comp.tex}
\vrule
\input{n_control_switch.tex}
\caption{On the left: Parallel composition operator; On the right: n control switches automaton}
\label{fig:hisim}
\end{figure}
Figure \ref{fig:hisim} introduces two related open automata with same holes \(\mbrc{l, r}\).
The automaton on the left is a parallel composition: any hole can perform actions at any time, the actions are passed unmodified and no synchronisation is performed.
The automaton on the right is a sequential composition with \(n\) control switches: a hole performs a sequence of actions then the other does, there are \(n\) seqences of a single automaton doing actions without the other performing some.

Intuitively the right automaton is a refinement of the left automaton because the left automaton is what happens when there was no bound \(n\) in the right automaton.
\[ R \defobject \mbrc{\mpar{l, ||} \mapsto \top, \mpar{r, ||} \mapsto \top} \]
\(R\) is a hole-identical simulation of \(n\) control switches by parallel composition.
There are enough examples of proofs of refinement in this article for the reader to be able to prove it as an exercise.
\end{exi}

\subsection{Example of hole-subset simulation}
Example of Appendix \ref{apx:composition} can be reused here.
The automaton on Figure \ref{fig:tlf} is a refinement of the one on Figure \ref{fig:tls} by limited composition correctness (Proposition \ref{prop:cc'}).

It is a simplified version of the motivation for making a refinement relation, which is the traffic light system in an article about weak-bisimulation \cite{wang:03126313}.
It had to be modified because here the simulation is a strong-simulation.

\subsection{Example of hole-superset simulation}
% TODO: vending machine of the presentation + money module


\section{Proofs of properties for hole-\(\triangle\) simulation}\label{apx:ophts}

\subsection{Hole-\(\triangle\) simulation is a pre-simulation}\label{apx:presim}
Let \(R\) be a relation on configurations.
The condition \(\sigma_{01} \uplus \sigma_{02} \vdash R\mpar{s_{01}, s_{02}}\) is in both definitions and the deadlock prevention requirement will not be used so proving the following is sufficient:
\begin{multline}
	\forall \mpar{s_1, s_2} \in S_1 \times S_2, \\
	\mpar{\everymath{\displaystyle}\begin{array}{l}
		\bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \bigsymb{\exists} \mpar{t_{2x} \defobject \OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X}, \\
		\quad \mpar{\forall x \in X, J'_{2x} \cap J_1 = J'_1 \cap J_2} \\[-10pt]
		\nwedge V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\begin{array}{l}
			\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \\[12pt]
			\nwedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
		\end{array}}
	\end{array}} \hyp{0}
\end{multline}
\[ \bigsymb{\implies} \]\vspace{-1cm}
\begin{multline}
	\bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \forall \sigma: V_1 \uplus V_2 \uplus \fvars{t_1} \to \values, \\
	\mpar{\sigma \vdash R\mpar{s_1, s_2} \wedge g_1} \implies \bigsymb{\exists} t_2 \defobject \OTx{2}{}{2}{2} \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \\
	\sigma \uplus \nu \vdash \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge g_2 \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2} \goal{0}
\end{multline}
\begin{proof} Let \(\mpar{s_1, s_2} \in S_1 \times S_2\), \nmm{t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}} and \(\sigma: V_1 \uplus V_2 \uplus \fvars{t_1} \to \values\) be such that
\[ \sigma \vdash R\mpar{s_1, s_2} \wedge g_1 \hyp{1} \]
In order to get the transition required to prove
\begin{multline}
	\bigsymb{\exists} t_2 \defobject \OTx{2}{}{2}{2} \in \fOT{s_2}, \exists \nu: \fvars{t_2} \to \values, \\
	\sigma \uplus \nu \vdash \alpha_1 = \alpha_2 \wedge \bigwedge_\subbox{j \in J'_1 \cap J'_2} \beta_{1j} = \beta_{2j} \wedge g_2 \wedge R\mpar{s'_1, s'_2}\psubst{\psi_1 \uplus \psi_2} \goal{0'}
\end{multline}
we use the hypothesis \hyp{0} with the transition \(t_1\) and get a family of transitions
\[ \mpar{t_{2x} \defobject \OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X} \]
such that the two following properties hold
\begin{gather}
	\forall x \in X, J'_{2x} \cap J_1 = J'_1 \cap J_2 \hyp{2} \\
	V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\everymath{\displaystyle}\begin{array}{l}
		\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \\[12pt]
		\nwedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
	\end{array}} \hyp{3}
\end{gather}
\hyp{3} holds for every values of the variables in \(V_1 \uplus V_2 \uplus \fvars{t_1}\) so in particular with the ones given by \(\sigma\).
We gather the variables of the implicit \(\exists\) in a valuation \nmm{\nu: \biguplus_{x \in X} \fvars{t_{2x}} \to \values}.
\[ \sigma \uplus \nu \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \bigvee_{x \in X} \mpar{\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \wedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}} \hyp{3'} \]
The left side of the implication is proved by \hyp{1}, and for the right side we get \(x \in X\) such that
\[ \sigma \uplus \nu \vdash \alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \wedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}} \hyp{4} \]
We have \(J'_{2x} \cap J_1 = J'_{2x} \cap J'_1\) in \hyp{4}:
\begin{align*}
	J'_{2x} \cap J_1 & \subseteq J'_{2x} \tag{1} \\
	J'_{2x} \cap J_1 & = J'_1 \cap J_2 & \text{by \hyp{2}} \\
	& \subseteq J'_1 \tag{2} \\
	J'_{2x} \cap J_1 & \subseteq J'_{2x} \cap J'_1 & \text{by (1) and (2)} \tag{3} \\
	J'_{2x} \cap J'_1 & \subseteq J'_{2x} \cap J_1 & \text{by } J'_1 \subseteq J_1 \tag{4} \\
	J'_{2x} \cap J_1 & = J'_{2x} \cap J'_1 & \text{by (3) and (4)}
\end{align*}
So we can prove \goal{0'} for the transition \(t_{2x}\) and the valuation \(\nu\) by \hyp{4}.
\end{proof}

\subsection{Context refinement for hole-equal simulation}
Let \(A_1 \defobject \OAg[1]\), \(A_2 \defobject \OAg[2]\) and \(A_3 \defobject \OAg[3]\) be three open automata.
Let \(k \in J_1\), \(A_{13} \defobject A_1\subst{A_3}{k}\) and \(A_{23} \defobject A_2\subst{A_3}{k}\) with \(A_{13} = \OAg[13]\) and \(A_{23} = \OAg[23]\).
Let \(R_{12}\) be a hole-equal simulation of \(A_1\) by \(A_2\) and \(\reach{A_{13}}\) be a witness that \(A_{13}\) is non-locking.
\[ R \defobject \mpar{\mpar{s_1, s_{31}}, \mpar{s_2, s_{32}}} \mapsto \choice{R_{12}\mpar{s_1, s_2} \wedge \reach{A_{13}}\mpar{s_1, s_{31}} \wedge \bigwedge_\subbox{v_3 \in V_3} v_{31} = v_{32} & \text{if } s_{31} = s_{32} \\ \bot & \text{otherwise}} \]
Where \(y_{3x}\) is the renaming of \(y_3\) from \(A_3\) in \(A_{x3}\).
We want to prove that \(R\) is a hole-equal simulation of \(A_{12}\) by \(A_{23}\).
\begin{proof}
\item[1)] \(J_{13} = J_3 \cup J_1 \setminus \mbrc{k} = J_3 \cup J_2 \setminus \mbrc{k} = J_{23}\) by \(J_1 = J_2\).
\item[2)] For \(\sigma_{013} \uplus \sigma_{023} \vdash R\mpar{s_{013}, s_{023}}\) we use the fact that \(R_{12}\) relates inital configurations and initial configuration is reachable:
	\begin{align*}
		& \sigma_{013} \uplus \sigma_{023} \vdash R\mpar{s_{013}, s_{023}} \\
		\iff & R\mpar{\mpar{s_{01}, s_{031}}, \mpar{s_{02}, s_{031}}}\psubst{\sigma_{01} \uplus \sigma_{02} \uplus \sigma_{031} \uplus \sigma_{032}} \\
		\iff & R_{12}\mpar{s_{01}, s_{02}}\psubst{\sigma_{01} \uplus \sigma_{02}} \wedge \reach{A_{13}}\mpar{s_{013}}\psubst{\sigma_{013}} \wedge \mpar{\bigwedge_{v_3 \in V_3} v_{31} = v_{32}}\psubst{\sigma_{031} \uplus \sigma_{032}} \\
		\iff & \mpar{\sigma_{01} \uplus \sigma_{02} \vdash R_{12}\mpar{s_{01}, s_{02}}} \wedge \mpar{\sigma_{013} \vdash \reach{A_{13}}\mpar{s_{013}}} \wedge \bigwedge_\subbox{v_3 \in V_3} \sigma_{031}\mpar{v_{31}} = \sigma_{032}\mpar{v_{32}} \\
		\iff & \mpar{\sigma_{01} \uplus \sigma_{02} \vdash R_{12}\mpar{s_{01}, s_{02}}} \wedge \mpar{\sigma_{013} \vdash \reach{A_{13}}\mpar{s_{013}}} \wedge \top
	\end{align*}
\item[3)] Let \(s_{13} \defobject \mpar{s_1, s_{31}} \in S_{13}\) and \(s_{23} \defobject \mpar{s_2, s_{32}} \in S_{23}\).
	We want to prove both
	\begin{align*}
		& \bigsymb{\forall} t_{13} \defobject \OTx{13}{}{13}{13} \in \fOT{s_{13}}, \bigsymb{\exists} \mpar{t_{23x} \defobject \OTx{23}{x}{23x}{23x} \in \fOT{s_{23}}}^{x \in X}, \\
		& \quad \mpar{\forall x \in X, J'_{23x} \cap J_{13} = J'_{13} \cap J_{23}} \\[-10pt]
		& \nwedge V_{13} \uplus V_{23} \uplus \fvars{t_{13}} \vdash R\mpar{s_{13}, s_{23}} \wedge g_{13} \Rightarrow \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\!\!\everymath{\displaystyle}\begin{array}{l}
			\alpha_{13} = \alpha_{23x} \wedge \bigwedge_\subbox{j \in J'_{23x} \cap J_{13}} \beta_{13j} = \beta_{23xj} \\[12pt]
			\nwedge g_{23x} \wedge R\mpar{s'_{13}, s'_{23x}}\psubst{\psi_{13} \uplus \psi_{23x}}
		\end{array}\!\!} \goal{0}
	\end{align*}
	\[ V_{13} \uplus V_{23} \uplus \biguplus_\subbox{t_{23} \in \fOT{s_{23}}} \fvars{t_{23}} \vdash R\mpar{s_{13}, s_{23}} \wedge \bigvee_\subbox{t_{23} \in \fOT{s_{23}}} \fguard{t_{23}} \implies \bigvee_\subbox{t_{13} \in \fOT{s_{13}}} \fguard{t_{13}} \goal{1} \]
	Let \nmm{t_{13} \defobject \OTx{13}{}{13}{13} \in \fOT{s_{13}}}, we use the fact that \(R_{12}\) is a simulation from the states \(\mpar{s_1, s_2}\) to get the hypothesis:
	\begin{align*}
		& \bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \bigsymb{\exists} \mpar{t_{2x} \defobject \OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X}, \\
		& \quad \mpar{\forall x \in X, J'_{2x} \cap J_1 = J'_1 \cap J_2} \\[-10pt]
		& \nwedge V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \\[12pt]
			\nwedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
		\end{array}} \hyp{1}
	\end{align*}
	Transition \(t_{13}\) is obtained in \(A_{13}\) by composition of two transitions \nmm{t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}} and \nmm{t_{31} \defobject \OTx{31}{}{31}{31} \in \fOT{s_{31}}} if \(k \in J'_1\) or by a the first transition and a fixed state \(s_{31}\) if \(k \notin J'_1\).
	We use \hyp{1} with the transition \(t_1\) to get
	\begin{gather*}
		\mpar{t_{2x} \defobject \OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X} \\
		\forall x \in X, J'_{2x} \cap J_1 = J'_1 \cap J_2 \hyp{1'} \\
		V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \\[12pt]
			\nwedge g_{2x} \wedge R\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
		\end{array}} \hyp{1"}
	\end{gather*}
	To build the family of transitions we need to know if \(k \in J'_{2x}\) for a every \(x \in X\):
	\begin{align*}
		J'_1 & = J'_1 \cap J_1 \\
		& = J'_1 \cap J_2 & \text{by } J_1 = J_2 \\
		& = J'_{2x} \cap J_1 & \text{by \hyp{1'}} \\
		& = J'_{2x} \cap J_2 & \text{by } J_1 = J_2 \\
		& = J'_{2x} \hyp{2}
	\end{align*}
	In the case \(s_{31} \neq s_{32}\) we can give the empty family, it won't cause any issue.
	Otherwise \(s_{31} = s_{32}\) so we can copy \(t_{31}\) into \nmm{t_{32} = \OTx{32}{}{32}{32}} to avoid conflicts.
	We also name \(t_3\) the original transition from \(T_3\).
	Using \hyp{2} we can build the familly of transition generated by the family \(t_{2x}^{x \in X}\):
	\[ t_{23x}^{x \in X} \defobject x \mapsto \choice{
		\OT{\mpar{s_2, s_{32}}}{\mpar{s'_{2x}, s'_{32}}}{\alpha_{2x}}{\beta_{2xj}^{j \in J'_{2x} \setminus \mbrc{k}} \uplus \beta_{3j}^{j \in J'_{32}}}{g_{2x} \wedge g_{32} \wedge \alpha_{32} = \beta_{2xk}}{\psi_{2x} \uplus \psi_{32}} & \text{if } k \in J'_{2x} \\
		\OT{\mpar{s_2, s_{32}}}{\mpar{s'_{2x}, s_{32}}}{\alpha_{2x}}{\beta_{2xj}^{j \in J'_2}}{g_2}{\psi_2} & \text{otherwise}
	} \]
	We will prove \goal{0} for the family \(t_{23x}^{x \in X}\), the new goals are
	\begin{gather}
		\forall x \in X, J'_{23x} \cap J_{13} = J'_{13} \cap J_{23} \goal{0'} \\
		V_{13} \uplus V_{23} \uplus \fvars{t_{13}} \vdash R\mpar{s_{13}, s_{23}} \wedge g_{13} \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha_{13} = \alpha_{23x} \wedge \bigwedge_\subbox{j \in J'_{23x} \cap J_{13}} \beta_{13j} = \beta_{23xj} \\[12pt]
			\nwedge g_{23x} \wedge R\mpar{s'_{13}, s'_{23x}}\psubst{\psi_{13} \uplus \psi_{23x}}
		\end{array}} \goal{2}
	\end{gather}
\item[\goal{0'}:] Let \(x \in X\), by case on \(k \in J'_1\):
	\begin{align*}
		\text{If } k \in J'_1: && J'_{23x} \cap J_{13} & = \mpar{J'_{31} \cup J'_{2x} \setminus \mbrc{k}} \cap \mpar{J_3 \cup J_1 \setminus \mbrc{k}} \\
		&&& = \mpar{J'_{31} \cap J_3} \cup \mpar{J'_{2x} \cap J_1} \setminus \mbrc{k} \\
		&&& = \mpar{J'_{31} \cap J_3} \cup \mpar{J'_1 \cap J_2} \setminus \mbrc{k} & \text{by \hyp{1'}} \\
		&&& = \mpar{J'_{31} \cup J'_1 \setminus \mbrc{k}} \cap \mpar{J_3 \cup J_2 \setminus \mbrc{k}} \\
		&&& = J'_{13} \cap J_{23} \\
		\text{If } k \notin J'_1: && J'_{23x} \cap J_{13} & = \mpar{J'_{2x} \setminus \mbrc{k}} \cap \mpar{J_1 \setminus \mbrc{k}} \\
		&&& = J'_{2x} \cap J_1 & \text{by } k \notin J'_1 = J'_{2x} \text{ \hyp{2}} \\
		&&& = J'_1 \cap J_2 & \text{by \hyp{1'}} \\
		&&& = \mpar{J'_1 \setminus \mbrc{k}} \cap \mpar{J_2 \setminus \mbrc{k}} & \text{by } k \notin J'_1 \\
		&&& = J'_{13} \cap J_{23}
	\end{align*}
\item[\goal{2}:] Let \(\sigma: V_{13} \uplus V_{23} \uplus \fvars{t_{13}} \to \values\).
	We use dummy values for the variables in \nmm{\biguplus_{x \in X} \fvars{t_{23x}}} to get the left side of the implication as an hypothesis (independant from these values):
	\[ \sigma \vdash R\mpar{s_{13}, s_{23}} \wedge g_{13} \hyp{3} \]
	If \(s_{31} \neq s_{32}\) then this hypothesis is \(\sigma \vdash \bot\), the empty family works and the proof is finished.
	We can assume \(s_{31} = s_{32}\) and break \hyp{3} into
	\begin{gather}
		\sigma \vdash R_{12}\mpar{s_1, s_2} \hyp{3a} \\
		\sigma \vdash \reach{A_{13}}\mpar{s_{13}} \hyp{3b} \\
		\sigma \vdash \bigwedge_\subbox{v_3 \in V_3} v_{31} = v_{32} \hyp{3c} \\
		\sigma \vdash g_{13} \hyp{3d}
	\end{gather}
	We use \hyp{1"} with valuation \(\sigma\) on variables \(V_1 \uplus V_2 \uplus \fvars{t_1}\), which is possible because the composition of transitions doesn't remove any variable (the simplification steps do, they give bisimilar automata).
	Then we get the values of the implicit \(\exists\) in \nmm{\nu: \biguplus_{x \in X} \fvars{t_{2x}}}.
	The left side of the implication is proved with \hyp{3a} and \hyp{3d}.
	So we get a \(x \in X\) such that
	\begin{gather}
		\sigma \uplus \nu \vdash \alpha_1 = \alpha_{2x} \hyp{4a} \\
		\sigma \uplus \nu \vdash \bigwedge_\subbox{j \in J'_{2x} \cap J_1} \beta_{1j} = \beta_{2xj} \hyp{4b} \\
		\sigma \uplus \nu \vdash g_{2x} \hyp{4c} \\
		\sigma \uplus \nu \vdash R_{12}\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}} \hyp{4d}
	\end{gather}
	If \(k \in J'_1\), we extend the valuation \(\nu\) to cover the variables of \(t_3\) in \(t_{23x}\) using their value in \(t_{13}\), \(\nu' \defobject \nu \uplus \mset{v_{32} \mapsto \sigma\mpar{v_{31}}}{v_3 \in \fvars{t_3}}\)
	Otherwise \(\nu' \defobject \nu\).
	We progress on \goal{2} by giving the valuation \(\sigma \uplus \nu'\) to the implicit \(\exists\), admitting the left side of the implication and choosing to prove the branch \(x\) of the disjunction:
	\begin{gather}
		\sigma \uplus \nu' \vdash \alpha_{13} = \alpha_{23x} \goal{3a} \\
		\sigma \uplus \nu' \vdash \bigwedge_\subbox{j \in J'_{23x} \cap J_{13}} \beta_{13j} = \beta_{23xj} \goal{3b} \\
		\sigma \uplus \nu' \vdash g_{23x} \goal{3c} \\
		\sigma \uplus \nu' \vdash R\mpar{s'_{13}, s'_{23x}}\psubst{\psi_{13} \uplus \psi_{23x}} \goal{3d}
	\end{gather}
	Because composition doesn't change the produced actions nor its variables, \goal{3a} is proved by \hyp{4a}.
	\goal{3b} holds because the valuations for the actions of the holes in \(J_3\) coincide by definition of \(\nu'\) and by \hyp{4b} for the others.
	For \goal{3c} we have two cases, if \(k \notin J'_1\) then \(g_{23x} \equiv g_{2x}\) and \hyp{4c} is sufficient, if \(k \in J'_1\) then \(g_{23x} \equiv g_{2x} \wedge g_3 \wedge \alpha_3 = \beta_{2xk}\) so we also need \hyp{3d} (\(g_{13} \equiv g_1 \wedge g_3 \wedge \alpha_3 = \beta_{1k}\)) and \hyp{4b} for the value \(k\) (\(\beta_{1k} = \beta_{2xk}\)).
	\goal{3d} is proved using \hyp{4d}, \hyp{3b} with the preservation of reachability across transitions (+ \hyp{3d}), \hyp{3c} and the fact that \(A_3\) performs the same transition with same values in both composed automata:
	\begin{align*}
		& \sigma \uplus \nu' \vdash R\mpar{s'_{13}, s'_{23x}}\psubst{\psi_{13} \uplus \psi_{23x}} \\
		\iff & \sigma \uplus \nu' \vdash \mpar{R_{12}\mpar{s'_1, s'_{2x}} \wedge \reach{A_{13}}\mpar{s'_{13}} \wedge \bigwedge_\subbox{v_3 \in V_3} v_{31} = v_{32}}\psubst{\psi_1 \uplus \psi_{31} \uplus \psi_{2x} \uplus \psi_{32}} \\
		\iff & \sigma \uplus \nu' \vdash R_{12}\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}} \wedge \reach{A_{13}}\mpar{s'_{13}}\psubst{\psi_{13}} \wedge \bigwedge_\subbox{v_3 \in V_3} \psi_{31}\mpar{v_{31}} = \psi_{32}\mpar{v_{32}} \\
		\iff & \sigma \uplus \nu' \vdash R_{12}\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}} \wedge \reach{A_{13}}\mpar{s'_{13}}\psubst{\psi_{13}} \wedge \bigwedge_\subbox{v_3 \in V_3 \cup \fvars{t_3}} v_{31} = v_{32} \\
		\iff & \mpar{\sigma \uplus \nu \vdash R_{12}\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}} \wedge \mpar{\sigma \vdash \reach{A_{13}}\mpar{s'_{13}}\psi_{13}} \wedge \mpar{\sigma \vdash \bigwedge_\subbox{v_3 \in V_3} v_{31} = v_{32}}
	\end{align*}
\item[\goal{1}:] Let \nmm{\sigma: V_{13} \uplus V_{23} \uplus \biguplus_\subbox{t_{23} \in \fOT{s_{23}}} \fvars{t_{23}} \to \values}.
	We use dummy values for the variables in \nmm{\biguplus_\subbox{t_{13} \in \fOT{s_{13}}} \fvars{t_{13}}} to get the left side of the implication (independant from these values), immediately broken into
	\begin{gather}
		\sigma \vdash R_{12}\mpar{s_1, s_2} \hyp{5a} \\
		\sigma \vdash \reach{A_{13}}\mpar{s_{13}} \hyp{5b} \\
		\sigma \vdash \bigvee_\subbox{t_{23} \in \fOT{s_{23}}} \fguard{t_{23}} \hyp{5c}
	\end{gather}
	\(R_{12}\) is a simulation and \(\reach{A_{13}}\) witnesses the non-locking composition so we have the hypotheses:
	\begin{gather}
		V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \vdash R_{12}\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \hyp{6} \\
		V_{13} \uplus \biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1} \vdash \reach{A_{13}}\mpar{s_{13}} \wedge \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \implies \bigvee_\subbox{t_{13} \in \fOT{s_{13}}} \fguard{t_{13}} \hyp{7}
	\end{gather}
	We use \hyp{6} with valuation \(\sigma\) projected on the variables from generating transitions in \(A_2\) to get \nmm{\nu: \biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1} \to \values}.
	The left side of the implication is proved using \hyp{5a} and \hyp{5c} because the guards from transitions of \(A_2\) are still in transitions of \(A_{23}\), the right side gives:
	\[ \sigma \uplus \nu \vdash \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \hyp{6'} \]
	We then use \hyp{7} with valuation \(\sigma \uplus \nu\) to get \nmm{\nu': \biguplus_\subbox{t_{13} \in \fOT{s_{13}}} \fvars{t_{13}}}.
	The left side of the implication is proved using \hyp{5b} and \hyp{6'}, the right side gives:
	\[ \sigma \uplus \nu' \vdash \bigvee_\subbox{t_{13} \in \fOT{s_{13}}} \fguard{t_{13}} \hyp{7'} \]
	\goal{1} is proved for valuation \(\nu'\) by admitting the left side and using \hyp{7'}.
\end{proof}

\subsection{Limited composition correctness for hole-subset simulation}
Let \(A_1 \defobject \OAg[1]\) and \(A_2 \defobject \OAg[2]\) be open automata, where \(J_2 = \emptyset\).
Let \(k \in J_1\) and \(A \defobject A_1\subst{A_2}{k}\), with \(A = \OAg\).
Let \(\reach{A}\) be a witness that \(A\) is non-locking.
\[ R \defobject \mpar{\mpar{s_{1'}, s_2}, s_1} \mapsto \choice{\reach{A}\mpar{s_{1'}, s_2} \wedge \bigwedge_\subbox{v_1 \in V_1} v_{1'} = v_1 & \text{if } s_{1'} = s_1 \\ \bot & \text{otherwise}} \]
Where \(y_{1'}\) is the renaming of \(y_1\) from \(A_1\) in \(A\).
We want to prove that \(R\) is a hole-subset simulation of \(A\) by \(A_1\).
\begin{proof}
\item[1)] \(J = J_2 \cup J_1 \setminus \mbrc{k} = \emptyset \cup J_1 \setminus \mbrc{k} \subseteq J_1\)
\item[2)] We use the fact that \(R\) doesn't constrain the behaviour of \(J_2\):
	\begin{align*}
		\sigma_0 \uplus \sigma_{01} \vdash R\mpar{s_0, s_{01}} \iff & \mpar{\bigwedge_{v_1 \in V_1} v_{1'} = v_1}\psubst{\sigma_{01'} \uplus \sigma_{02} \uplus \sigma_{01}} \\
		\iff & \bigwedge_\subbox{v_1 \in V_1} \sigma_{01'}\mpar{v_{1'}} = \sigma_{01}\mpar{v_1} \\
		\iff & \top
	\end{align*}
\item[3)] Let \(s \defobject \mpar{s_{1'}, s_2} \in S\) and \(s_1 \in S_1\).
	We want to prove both
	\begin{align*}
		& \bigsymb{\forall} t \defobject \OTg \in \fOT{s}, \bigsymb{\exists} \mpar{t_{1x} \defobject \OTx{1}{x}{1x}{1x} \in \fOT{s_1}}^{x \in X}, \\
		& \quad \mpar{\forall x \in X, J'_{1x} \cap J = J' \cap J_1} \\[-10pt]
		& \nwedge V \uplus V_1 \uplus \fvars{t} \vdash R\mpar{s, s_1} \wedge g \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha = \alpha_{1x} \wedge \bigwedge_\subbox{j \in J'_{1x} \cap J} \beta_j = \beta_{1xj} \\[12pt]
			\nwedge g_{1x} \wedge R\mpar{s', s'_{1x}}\psubst{\psi \uplus \psi_{1x}}
		\end{array}} \goal{0}
	\end{align*}
	\[ V \uplus V_1 \uplus \biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1} \vdash R\mpar{s, s_1} \wedge \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \implies \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \goal{1} \]
	Let \nmm{t \defobject \OTg \in \fOT{s}}, we know that \(t\) is obtained by composition so there is a generating transition \(t_1 \in \fOT{s_1}\) for which we will prove \goal{0}.
	If \(s_{1'} \neq s_1\) we instead prove \goal{0} with the empty family.
	\begin{gather}
		\forall x \in X, J'_1 \cap J = J' \cap J_1 \goal{0'} \\
		V \uplus V_1 \uplus \fvars{t} \vdash R\mpar{s, s_1} \wedge g \implies \alpha = \alpha_1 \wedge \bigwedge_\subbox{j \in J'_1 \cap J} \beta_j = \beta_{1j} \wedge g_1 \wedge R\mpar{s', s'_1}\psubst{\psi \uplus \psi_1} \goal{2}
	\end{gather}
\item[\goal{0'}:] \(t\) is a transition built from \(t_1\) so it has its holes.
	Additionnally either \(k \notin J'_1\) so \(J' = J'_1\) or \(k \in J'_1\) so \(J' = \emptyset \cup J'_1 \setminus \mbrc{k}\) because \(A_2\) has no holes.
	Either case \(J'_1 \cap J = J'_1 \setminus \mbrc{k} = \mpar{J'_1 \setminus \mbrc{k}} \cap J_1 = J' \cap J_1\).
\item[\goal{2}:] Let \(\sigma: V \uplus V_1 \uplus \fvars{t} \to \values\).
	We rename some variables in the input domain of \(\sigma\) to get \(\nu: \fvars{t_1} \to \values\).
	We use \(\nu\) to prove \goal{2}, get the left side of the implication as an hypothesis and break the right side of the implication:
	\begin{gather}
		\sigma \vdash R\mpar{s, s_1} \wedge g \hyp{1} \\
		\sigma \uplus \nu \vdash \alpha = \alpha_1 \goal{2a} \\
		\sigma \uplus \nu \vdash \bigwedge_\subbox{j \in J'_1 \cap J} \beta_j = \beta_{1j} \goal{2b} \\
		\sigma \uplus \nu \vdash g_1 \goal{2c} \\
		\sigma \uplus \nu \vdash R\mpar{s', s'_1}\psubst{\psi \uplus \psi_1} \goal{2d}
	\end{gather}
	If \(s_{1'} \neq s_1\) then \hyp{1} is \(\sigma \vdash \bot\) so the proof is finished and the empty family worked.
	Otherwise we can assume \(s_{1'} = s_1\) and break \hyp{1} into
	\begin{gather}
		\sigma \vdash \reach{A}\mpar{s} \hyp{1a} \\
		\sigma \vdash \bigwedge_\subbox{v_1 \in V_1} v_{1'} = v_1 \hyp{1b} \\
		\sigma \vdash g \hyp{1c}
	\end{gather}
	\goal{2a} holds because composition doesn't change the produced action and the valuation coincide on the renamed variables.
	\goal{2b} also holds because \(J'_1 \cap J = J'_1 \setminus \mbrc{k} = J'\), composition doesn't change the actions of the holes involved and the valuation coincide on the renamed variables.
	\goal{2c} is proved using \hyp{1c} (\(g \equiv g_1\) or \(g \equiv g_1 \wedge \dots\)).
	For \goal{2d} we use \hyp{1a} with the preservation of reachability across transitions (+ \hyp{1b}), \hyp{1b} and the fact that the valuations coincide on the renamed values:
	\begin{align*}
		& \sigma \uplus \nu \vdash R\mpar{s', s'_1}\psubst{\psi \uplus \psi_1} \\
		\iff & \sigma \uplus \nu \vdash \mpar{\reach{A}\mpar{s} \wedge \bigwedge_{v_1 \in V_1} v_{1'} = v_1}\psubst{\psi \uplus \psi_1} \\
		\iff & \sigma \uplus \nu \vdash \reach{A}\mpar{s}\psubst{\psi} \wedge \bigwedge_\subbox{v_1 \in V_1} \psi_{1'}\mpar{v_{1'}} = \psi\mpar{v_1} \\
		\iff & \sigma \uplus \nu \vdash \reach{A}\mpar{s}\psubst{\psi} \wedge \bigwedge_\subbox{v_1 \in V_1 \cup \fvars{t_1}} v_{1'} = v_1 \\
		\iff & \mpar{\sigma \vdash \reach{A}\mpar{s}\psubst{\psi}} \wedge \mpar{\sigma \uplus \nu \vdash \bigwedge_\subbox{v_1 \in V_1} v_{1'} = v_1}
	\end{align*}
\item[\goal{1}:] % TODO: adapt and continue
	Let \nmm{\sigma: V \uplus V_1 \uplus \biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1} \to \values}.
	We use dummy values for the variables in \nmm{\biguplus_\subbox{t \in \fOT{s}} \fvars{t}} to get the left side of the implication (independant from these values), immediately broken into
	\begin{gather}
		\sigma \vdash \reach{A}\mpar{s} \hyp{2a} \\
		\sigma \vdash \bigwedge_\subbox{v_1 \in V_1} v_{1'} = v_1 \hyp{2b} \\
		\sigma \vdash \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \hyp{2c}
	\end{gather}
	\(\reach{A}\) is a witness of the non-locking composition so we have the hypothesis:
	\[ V \uplus \biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1} \vdash \reach{A}\mpar{s} \wedge \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \implies \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \hyp{3} \]
	We use \hyp{3} with valuation \(\sigma\) to get \nmm{\nu: \biguplus_\subbox{t \in \fOT{s}} \fvars{t} \to \values}.
	The left side of the implication is proved with \hyp{2a} and \hyp{2c}, the right side gives the hypothesis:
	\[ \sigma \uplus \nu \vdash \bigvee_\subbox{t \in \fOT{s}} \fguard{t} \hyp{3'} \]
	We prove \goal{1} with valuation \(\nu\) by admitting the left side ofthe implication and using \hyp{3}.
\end{proof}

\subsection{Special composition correctness for hole-superset simulation}
Let \(A_1 \defobject \OAg[1]\), \(A_2 \defobject \OAg[2]\) and  \(A_3 \defobject \OAg[3]\) be open automata.
Let \(k \in J_1 \setminus J_2\) and \(A \defobject A_1\subst{A_3}{k}\), with \(A = \OAg\).
Let \(R_{12}\) be a hole-superset simulation of \(A_1\) by \(A_2\) and \(\reach{A}\) be a witness that \(A\) is non-locking.
\[ R \defobject \mpar{\mpar{s_1, s_3}, s_2} \mapsto R_{12}\mpar{s_1, s_2} \wedge \reach{A_1\subst{A_3}{k}}\mpar{s_1, s_3} \]
We want to prove that \(R\) is a hole-superset simulation of \(A\) by \(A_2\).
\begin{proof}
\item[1)] % TODO
\item[2)] % TODO
\item[3)] % TODO
\end{proof}

\section{Proof of transitivity}\label{apx:trans}
Let \(A_1 \defobject \OAg[1]\), \(A_2 \defobject \OAg[2]\) and \(A_3 \defobject \OAg[3]\) be open automata.
Let \(R_{12}\) be a hole-\(\triangle\) simulation of \(A_1\) by \(A_2\) and \(R_{23}\) of \(A_2\) by \(A_3\).
\[ R \defobject \mpar{s_1, s_3} \mapsto \exists V_2, \bigvee_\subbox{s_2 \in S_2} R_{12}\mpar{s_1, s_2} \wedge R_{23}\mpar{s_2, s_3} \]
We want to prove that \(R\) is a hole-\(\triangle\) simulation of \(A_1\) by \(A_3\).
\begin{proof}
\item[1)] By transitivity of \(\triangle\), \(J_1 \triangle J_3\)
\item[2)] We prove that initial configurations are related using \(\sigma_{02}\) as the values of the variables in \(V_2\), and \(s_{02}\) to choose the branch of the disjunction.
\begin{align*}
	\sigma_{01} \uplus \sigma_{03} \vdash R\mpar{s_{01}, s_{03}} \iff & \sigma_{01} \uplus \sigma_{03} \vdash \exists V_2, \bigvee_\subbox{s_2 \in S_2} R_{12}\mpar{s_{01}, s_2} \wedge R_{23}\mpar{s_2, s_{03}} \\
	\impliedby & \sigma_{01} \uplus \sigma_{02} \uplus \sigma_{03} \vdash R_{12}\mpar{s_{01}, s_{02}} \wedge R_{23}\mpar{s_{02}, s_{03}} \\
	\impliedby & \mpar{\sigma_{01} \uplus \sigma_{02} \vdash R_{12}\mpar{s_{01}, s_{02}}} \wedge \mpar{\sigma_{02} \uplus \sigma_{03} \vdash R_{23}\mpar{s_{02}, s_{03}}}
\end{align*}
\item[3)] Let \(\mpar{s_1, s_3} \in S_1 \times S_3\), we want to prove both
	\begin{align*}
		& \bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \bigsymb{\exists} \mpar{t_{3x} \defobject \OTx{3}{x}{3x}{3x} \in \fOT{s_3}}^{x \in X}, \\
		& \mpar{\forall x \in X, J'_{3x} \cap J_1 = J'_1 \cap J_3} \\[-10pt]
		& \wedge V_1 \uplus V_3 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_3} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha_1 = \alpha_{3x} \wedge \bigwedge_\subbox{j \in J'_{3x} \cap J_1} \beta_{1j} = \beta_{3xj} \\[12pt]
			\nwedge g_{3x} \wedge R\mpar{s'_1, s'_{3x}}\psubst{\psi_1 \uplus \psi_{3x}}
		\end{array}} \goal{0}
	\end{align*}
	\[ V_1 \uplus V_3 \uplus \biguplus_\subbox{t_3 \in \fOT{s_3}} \fvars{t_3} \vdash R\mpar{s_1, s_3} \wedge \bigvee_\subbox{t_3 \in \fOT{s_3}} \fguard{t_3} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \goal{1} \]
\item[\goal{0}:] Let \nmm{t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}}.
	For every \(s_2 \in S_2\) we have the hypotheses on \(R_{12}\) and \(R_{23}\):
	\begin{gather}
		\everymath{\displaystyle}\begin{array}{l}
		\bigsymb{\forall} t_1 \defobject \OTx{1}{}{1}{1} \in \fOT{s_1}, \bigsymb{\exists} \mpar{t_{s2x} \defobject \OTx{2}{x}{2x}{2x} \in \fOT{s_2}}^{x \in X}, \\
		\quad \mpar{\forall x \in X, J'_{s2x} \cap J_1 = J'_1 \cap J_2} \\[-10pt]
		\nwedge V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R_{12}\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\begin{array}{l}
			\alpha_1 = \alpha_{2x} \wedge \bigwedge_\subbox{j \in J'_{s2x} \cap J_1} \beta_{1j} = \beta_{2xj} \\[12pt]
			\nwedge g_{2x} \wedge R_{12}\mpar{s'_1, s'_{2x}}\psubst{\psi_1 \uplus \psi_{2x}}
		\end{array}}
		\end{array} \hyp{0} \\
		\everymath{\displaystyle}\begin{array}{l}
		\bigsymb{\forall} t_2 \defobject \OTx{2}{}{2}{2} \in \fOT{s_2}, \bigsymb{\exists} \mpar{t_{3x} \defobject \OTx{3}{x}{3x}{3x} \in \fOT{s_3}}^{x \in X}, \\
		\quad \mpar{\forall x \in X, J'_{3x} \cap J_2 = J'_2 \cap J_3} \\[-10pt]
		\nwedge V_2 \uplus V_3 \uplus \fvars{t_{s2}} \vdash R_{23}\mpar{s_2, s_3} \wedge g_2 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X} \mpar{\begin{array}{l}
			\alpha_2 = \alpha_{3x} \wedge \bigwedge_\subbox{j \in J'_{3x} \cap J_2} \beta_{2j} = \beta_{3xj} \\[12pt]
			\nwedge g_{3x} \wedge R_{23}\mpar{s'_2, s'_{3x}}\psubst{\psi_2 \uplus \psi_{3x}}
		\end{array}}
		\end{array} \hyp{1}
	\end{gather}
	We use hypothesis \hyp{0} with \(t_1\) for every \(s_2 \in S_2\) to get
	\begin{gather*}
		\mpar{t_{s2x} \defobject \OT{s_2}{s'_{s2x}}{\alpha_{s2x}}{\beta_{s2xj}^{j \in J'_{s2x}}}{g_{s2x}}{\psi_{s2x}} \in \fOT{s_2}}^{x \in X_{s2}} \\
		\forall x \in X, J'_{s2x} \cap J_1 = J'_1 \cap J_2 \hyp{0'} \\
		V_1 \uplus V_2 \uplus \fvars{t_1} \vdash R_{12}\mpar{s_1, s_2} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{x \in X_{s2}} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha_1 = \alpha_{s2x} \wedge \bigwedge_\subbox{j \in J'_{s2x} \cap J_1} \beta_{1j} = \beta_{s2xj} \\[12pt]
			\nwedge g_{s2x} \wedge R_{12}\mpar{s'_1, s'_{s2x}}\psubst{\psi_1 \uplus \psi_{s2x}}
		\end{array}} \hyp{0"}
	\end{gather*}
	Then use \hyp{1} with every \(t_{s2x}\) to get
	\begin{gather*}
		Z_{s2x} \defobject \mbrc{s_2} \times \mbrc{x} \times Y_{s2x} \\
		\mpar{t_{3z} \defobject \OTx{3}{z}{3z}{3z} \in \fOT{s_3}}^{z \in Z_{s2x}} \\
		\forall z \in Z_{s2x}, J'_{3z} \cap J_2 = J'_{s2x} \cap J_3 \hyp{1x} \\
		V_2 \uplus V_3 \uplus \fvars{t_{s2x}} \vdash R_{23}\mpar{s_2, s_3} \wedge g_{s2x} \Rightarrow \operatorname*{\bigsymb{\bigvee}}_\subbox{z \in Z_{s2x}} \mpar{\!\everymath{\displaystyle}\begin{array}{l}
			\alpha_{s2x} = \alpha_{3z} \wedge \bigwedge_\subbox{j \in J'_{3z} \cap J_2} \beta_{s2xj} = \beta_{3zj} \\[12pt]
			\nwedge g_{3z} \wedge R_{23}\mpar{s'_{s2x}, s'_{3z}}\psubst{\psi_{s2x} \uplus \psi_{3z}}
		\end{array}\!} \hyp{1x'}
	\end{gather*}
	We pose \nmm{Z \defobject \biguplus_{s_2 \in S_2} \biguplus_{x \in X_{s2}} Z_{s2x}}.
	We will prove \goal{0} for the family \(t_{3z}^{z \in Z}\).
	The new goals are:
	\begin{gather}
		\forall z \in Z, J'_{3z} \cap J_1 = J'_1 \cap J_3 \goal{0'} \\
		V_1 \uplus V_3 \uplus \fvars{t_1} \vdash R\mpar{s_1, s_3} \wedge g_1 \implies \operatorname*{\bigsymb{\bigvee}}_{z \in Z} \mpar{\everymath{\displaystyle}\begin{array}{l}
			\alpha_1 = \alpha_{3z} \wedge \bigwedge_\subbox{j \in J'_{3z} \cap J_1} \beta_{1j} = \beta_{3zj} \\[12pt]
			\nwedge g_{3z} \wedge R\mpar{s'_1, s'_{3z}}\psubst{\psi_1 \uplus \psi_{3z}}
		\end{array}} \goal{2}
	\end{gather}
\item[\goal{0'}:] By case on \(\triangle\):
	\begin{itemize}
	\item Let \(\triangle\) be \(\subseteq\).
		\begin{align*}
		J'_{3z} \cap J_1 & \subseteq J'_{3z} \cap J_2 & \text{by } & J_1 \subseteq J_2 \\
			& \subseteq J'_{2x} \cap J_3 & \text{by } & \text{\hyp{1x}} \hyp{2} \\
			& \subseteq J'_{2x} \cap J_3 \cap J_1 & \text{by } & J'_{3z} \cap J_1 \subseteq J_1 \\
			& \subseteq J'_{2x} \cap J_1 && \\
			& \subseteq J'_1 \cap J_2 & \text{by } & \text{\hyp{0'}} \hyp{2'} \\
			& \subseteq J'_1 \cap J_3 & \text{by } & J_2 \subseteq J_3
		\end{align*}
		\begin{align*}
		J'_1 \cap J_3 & = J'_1 = J'_1 \cap J_2 & \text{by } & J'_1 \subseteq J_1 \subseteq J_2 \subseteq J_3 \\
			& = J'_{2x} \cap J_1 & \text{by } & \text{\hyp{0'}} \\
			& \subseteq J'_{2x} \cap J_3 & \text{by } & J_1 \subseteq J_3 \\
			& \subseteq J'_{3z} \cap J_2 & \text{by } & \text{\hyp{1x}} \\
			& \subseteq J'_{3z} \cap J_2 \cap J_1 & \text{by } & J'_1 \subseteq J_1 \\
			& \subseteq J'_{3z} \cap J_1 &&
		\end{align*}
	\item Let \(\triangle\) be \(\supseteq\).
		\begin{align*}
		J'_1 \cap J_3 & \subseteq J'_1 \cap J_2 & \text{by } & J_3 \supseteq J_2 \\
			& \subseteq J'_{2x} \cap J_1 & \text{by } & \text{\hyp{0'}} \\
			& \subseteq J'_{2x} \cap J_1 \cap J_3 & \text{by } & J'_1 \cap J_3 \subseteq J_3 \\
			& \subseteq J'_{2x} \cap J_3 && \\
			& \subseteq J'_{3z} \cap J_2 & \text{by } & \text{\hyp{1x}} \\
			& \subseteq J'_{3z} \cap J_1 & \text{by } & J_1 \supseteq J_2
		\end{align*}
		\begin{align*}
		J'_{3z} \cap J_1 & = J'_{3z} = J'_{3z} \cap J_2 & \text{by } & J_1 \supseteq J_2 \supseteq J_3 \supseteq J'_{3z} \\
			& = J'_{2x} \cap J_3 & \text{by } & \text{\hyp{1x}} \hyp{3} \\
			& \subseteq J'_{2x} \cap J_1 & \text{by } & J_1 \supseteq J_3 \\
			& \subseteq J'_1 \cap J_2 & \text{by } & \text{\hyp{0'}} \hyp{3'} \\
			& \subseteq J'_1 \cap J_2 \cap J_3 & \text{by } & J'_{3z} \subseteq J_3 \\
			& \subseteq J'_1 \cap J_3 &&
		\end{align*}
	\item Let \(\triangle\) be \(=\).
		We combine the proofs for two above cases and get both inclusions so \goal{0'} holds.
	\end{itemize}
\item[\goal{2}:] Let \(\sigma_1: V_1 \uplus \fvars{t_1} \to \values\) and \(\sigma_3: V_3 \to \values\).
	We use dummy values for variables in \nmm{\biguplus_\subbox{z \in Z} \fvars{t_{3z}}} to get the left side of this implication as an hypothesis (independant from these values):
	\[ \sigma_1 \uplus \sigma_3 \vdash R\mpar{s_1, s_3} \wedge g_1 \hyp{4} \]
	Hypothesis immediately broken down into
	\begin{gather*}
		\sigma_2: V_2 \to \values \quad s_2 \in S_2 \\
		\sigma_1 \uplus \sigma_2 \uplus \sigma_3 \vdash R_{12}\mpar{s_1, s_2} \wedge R_{23}\mpar{s_2, s_3} \hyp{4'} \\
		\sigma_1 \vdash g_1 \hyp{4"}
	\end{gather*}
	We can use immediately \hyp{0"} with valuation \(\sigma_1 \uplus \sigma_2\) to get \nmm{\nu_2: \biguplus_{x \in X} \fvars{t_{2x}} \to \values}.
	The left side of the implication is proved with the right side of \hyp{4'} and \hyp{4"}, so we get \(x \in X_{s2}\) and the hypotheses
	\begin{align}
		\sigma_1 \uplus \sigma_2 \uplus \nu_2 & \vdash \alpha_1 = \alpha_{s2x} \hyp{5a} \\
		\sigma_1 \uplus \sigma_2 \uplus \nu_2 & \vdash \bigwedge_\subbox{j \in J'_1 \cap J_{s2x}} \beta_{1j} = \beta_{s2xj} \hyp{5b} \\
		\sigma_2 \uplus \nu_2 & \vdash g_{s2x} \hyp{5c} \\
		\sigma_1 \uplus \sigma_2 \uplus \nu_2 & \vdash R\mpar{s'_1, s'_{s2x}}\psubst{\psi_1 \uplus \psi_{s2x}} \hyp{5d}
	\end{align}
	We can now use \hyp{1x'} with valuation \(\sigma_2 \uplus \nu_2 \uplus \sigma_3\) to get \nmm{\nu_3: \biguplus_\subbox{Z \in Z_{s2x}} \fvars{t_{3z}} \to \values}.
	The left side of the implication is proved with the left side of \hyp{4'} and \hyp{4"}, so we get \(z \in Z_{s2x}\) and the hypotheses
	\begin{align}
		\sigma_2 \uplus \nu_2 \uplus \sigma_3 \uplus \nu_3 & \vdash \alpha_{s2x} = \alpha_{3z} \hyp{6a} \\
		\sigma_2 \uplus \nu_2 \uplus \sigma_3 \uplus \nu_3 & \vdash \bigwedge_\subbox{j \in J'_{s2x} \cap J_{3z}} \beta_{s2xj} = \beta_{3zj} \hyp{6b} \\
		\sigma_3 \uplus \nu_3 & \vdash g_{3z} \hyp{6c} \\
		\sigma_2 \uplus \nu_2 \uplus \sigma_3 \uplus \nu_3 & \vdash R\mpar{s'_{s2x}, s'_{3z}}\psubst{\psi_{s2x} \uplus \psi_{3z}} \hyp{6d}
	\end{align}
	Finally to prove \goal{2} with valuation \(\nu_3\) for the implicit \(\exists\), we admit the left side of the implication choose to prove the branch \(z\):
	\begin{align}
		\sigma_1 \uplus \sigma_3 \uplus \nu_3 & \vdash \alpha_1 = \alpha_{3z} \goal{2a} \\
		\sigma_1 \uplus \sigma_3 \uplus \nu_3 & \vdash \bigwedge_\subbox{j \in J'_{3z} \cap J_1} \beta_{1j} = \beta_{3zj} \goal{2b} \\
		\sigma_3 \uplus \nu_3 & \vdash g_{3z} \goal{2c} \\
		\sigma_1 \uplus \sigma_3 \uplus \nu_3 &\vdash R\mpar{s'_1, s'_{3z}}\psubst{\psi_1 \uplus \psi_{3z}} \goal{2d}
	\end{align}
	\goal{2a} is proved by transitivity using \hyp{5a} and \hyp{5a}.
	\goal{2b} is proved using \hyp{5b} and \hyp{6b}, but depending on \(\triangle\) the equality are obtained for the interesting values \(j\) using either \hyp{2} and \hyp{2'} or \hyp{3} and \hyp{3'}.
	\goal{2c} is exactly \hyp{6c}.
	We prove \goal{2d} with valuation \(\psi_{s2x}\psubst{\sigma_2 \uplus \nu_2}\) for the branch \(s_2\) using \hyp{5d} and \hyp{6d}:
	\begin{align*}
		& \sigma_1 \uplus \sigma_3 \uplus \nu_3 \vdash R\mpar{s'_1, s'_{3z}}\psubst{\psi_1 \uplus \psi_{3z}} \\
		\iff & \mpar{R_{12}\mpar{s_1, s_2} \wedge R_{23}\mpar{s_2, s_3}}\psubst{\psi_1 \uplus \psi_{3z}}\psubst{\psi_{s2x}\psubst{\sigma_2 \uplus \nu_2}}\psubst{\sigma_1 \uplus \sigma_3 \uplus \nu_3} \\
		\iff & R_{12}\mpar{s_1, s_2}\psubst{\psi_1}\psubst{\psi_{s2x}\psubst{\sigma_2 \uplus \nu_2}}\psubst{\sigma_1} \wedge R_{23}\mpar{s_2, s_3}\psubst{\psi_{3z}}\psubst{\psi_{s2x}\psubst{\sigma_2 \uplus \nu_2}}\psubst{\sigma_3 \uplus \nu_3} \\
		\iff & R_{12}\mpar{s_1, s_2}\psubst{\psi_1 \uplus \psi_{s2x}}\psubst{\sigma_2 \uplus \nu_2 \uplus \sigma_1} \wedge R_{23}\mpar{s_2, s_3}\psubst{\psi_{3z} \uplus \psi_{s2x}}\psubst{\sigma_2 \uplus \nu_2 \uplus \sigma_3 \uplus \nu_3} \\
		\iff & \mpar{\sigma_2 \uplus \nu_2 \uplus \sigma_1 \vdash R_{12}\mpar{s_1, s_2}\psubst{\psi_1 \uplus \psi_{s2x}}} \wedge \mpar{\sigma_2 \uplus \nu_2 \uplus \sigma_3 \uplus \nu_3 \vdash R_{23}\mpar{s_2, s_3}\psubst{\psi_{3z} \uplus \psi_{s2x}}}
	\end{align*}
\item[\goal{1}:] Let \(\sigma_1: V_1 \to \values\) and \nmm{\sigma_3: V_3 \uplus \biguplus_\subbox{t_3 \in \fOT{s_3}} \fvars{t_3} \to \values}.
	We have the hypotheses on \(R_{12}\) and \(R_{23}\) for the states \(s_1\) and \(s_3\), then the current goal:
	\begin{gather}
		\forall s_2 \in S_2, V_1 \uplus V_2 \uplus \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \vdash R_{12}\mpar{s_1, s_2} \wedge \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \hyp{7} \\
		\forall s_2 \in S_2, V_2 \uplus V_3 \uplus \biguplus_\subbox{t_3 \in \fOT{s_3}} \fvars{t_3} \vdash R_{23}\mpar{s_2, s_3} \wedge \bigvee_\subbox{t_3 \in \fOT{s_3}} \fguard{t_3} \implies \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \hyp{8} \\
		\sigma_1 \uplus \sigma_3 \vdash R\mpar{s_1, s_3} \wedge \bigvee_\subbox{t_3 \in \fOT{s_3}} \fguard{t_3} \implies \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \goal{1'}
	\end{gather}
	We use dummy values for variables in \nmm{\biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1}} to get the left side of this implication as an hypothesis (independant from these values):
	\[ \sigma_1 \uplus \sigma_3 \vdash R\mpar{s_1, s_3} \wedge \bigvee_\subbox{t_3 \in \fOT{s_3}} \fguard{t_3} \hyp{9} \]
	Hypothesis that we immediately break down into:
	\begin{gather*}
		\sigma_2: V_2 \to \values \quad s_2 \in S_2 \\
		\sigma_1 \uplus \sigma_2 \uplus \sigma_3 \vdash R_{12}\mpar{s_1, s_2} \wedge R_{23}\mpar{s_2, s_3} \hyp{9'} \\
		\sigma_1 \uplus \sigma_3 \vdash \bigvee_\subbox{t_3 \in \fOT{s_3}} \fguard{t_3} \hyp{9"}
	\end{gather*}
	We can use immediately \hyp{8} with state \(s_2\) and valuation \(\sigma_2 \uplus \sigma_3\) to get \nmm{\nu_2: \biguplus_\subbox{t_2 \in \fOT{s_2}} \fvars{t_2} \to \values}.
	The left side of the implication is proved with the right side of \hyp{9'} and \hyp{9"}, so we get
	\[ \sigma_3 \uplus \nu_2 \vdash \bigvee_\subbox{t_2 \in \fOT{s_2}} \fguard{t_2} \hyp{8'} \]
	We can now use \hyp{7} with state \(s_2\) and valuation \(\sigma_1 \uplus \sigma_2 \uplus \nu_2\) to get \nmm{\nu_1: \biguplus_\subbox{t_1 \in \fOT{s_1}} \fvars{t_1} \to \values}.
	The left side of the implication is proved with the left side of \hyp{9'} and \hyp{8'}, so we get
	\[ \sigma_1 \uplus \nu_1 \vdash \bigvee_\subbox{t_1 \in \fOT{s_1}} \fguard{t_1} \hyp{7'} \]
	Finally we can prove \goal{1'} with valuation \(\nu_1\) for the implicit \(\exists\) by admitting the left side of the implication and using \hyp{7'} for the right side.
\end{proof}

\end{document}